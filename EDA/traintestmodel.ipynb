{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import pandas as pd\r\n",
    "import math\r\n",
    "\r\n",
    "def magnitude(X, Y, Z):\r\n",
    "    return math.sqrt(float(X**2) + float(Y**2) + float(Z**2))\r\n",
    "\r\n",
    "\r\n",
    "path = 'gestures-dataset'\r\n",
    "\r\n",
    "dataset = None\r\n",
    "\r\n",
    "for subject in os.listdir(path):\r\n",
    "    if os.path.isfile(os.path.join(path, subject)):\r\n",
    "        continue\r\n",
    "    if subject in ('U01', 'U02', 'U03', 'U04', 'U05', 'U06', 'U07', 'U08'):\r\n",
    "        for gesture in os.listdir(os.path.join(path, subject)):\r\n",
    "            if os.path.isfile(os.path.join(path, subject, gesture)):\r\n",
    "                continue\r\n",
    "            gesture = str(gesture)\r\n",
    "            for samplefile in os.listdir(os.path.join(path, subject, gesture)):\r\n",
    "                if os.path.isfile(os.path.join(path, subject, gesture, samplefile)):\r\n",
    "                    df = pd.read_csv(os.path.join(path, subject, gesture, samplefile), \\\r\n",
    "                        sep = ' ', \\\r\n",
    "                        names = ['System.currentTimeMillis()', \\\r\n",
    "                        'System.nanoTime()', \\\r\n",
    "                        'sample.timestamp', \\\r\n",
    "                        'X', \\\r\n",
    "                        'Y', \\\r\n",
    "                        'Z' \\\r\n",
    "                        ])\r\n",
    "                    df = df[[\"sample.timestamp\", \"X\", \"Y\", \"Z\"]]\r\n",
    "                                        \r\n",
    "                    start = df[\"sample.timestamp\"][0]\r\n",
    "                    df[\"sample.timestamp\"] -= start\r\n",
    "                    df[\"sample.timestamp\"] /= 10000000\r\n",
    "                    df[\"subject\"] = subject\r\n",
    "                    df[\"gesture\"] = gesture\r\n",
    "                    df[\"sample\"] = str(samplefile[:-4])\r\n",
    "                    #print(df)\r\n",
    "                    if dataset is None:\r\n",
    "                        dataset = df.copy()\r\n",
    "                    else:\r\n",
    "                        dataset = pd.concat([dataset, df])\r\n",
    "\r\n",
    "dataset = dataset.sort_values(by=['gesture','subject','sample','sample.timestamp'])\r\n",
    "data = dataset\r\n",
    "#print(dataset)\r\n",
    "print(dataset.head(10))\r\n",
    "print(dataset.tail(10))\r\n",
    "\r\n",
    "                    \r\n",
    "            \r\n",
    "            "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   sample.timestamp         X         Y          Z subject gesture sample\n",
      "0               0.0  1.532289 -0.919373  10.113108     U01      01     01\n",
      "1              11.0  0.919373 -0.919373   9.959879     U01      01     01\n",
      "2              22.0  1.838747 -0.153229  10.726024     U01      01     01\n",
      "3              33.0  5.822699  3.371036  10.879252     U01      01     01\n",
      "4              44.0  6.435614  1.532289   9.193734     U01      01     01\n",
      "5              55.0  2.758120 -7.967903   9.193734     U01      01     01\n",
      "6              66.0  0.612916 -6.588843   8.887277     U01      01     01\n",
      "7              77.0  0.000000 -2.145205   9.653421     U01      01     01\n",
      "8              88.0 -0.153229 -1.685518   9.653421     U01      01     01\n",
      "9              99.0  0.306458 -0.306458   9.959879     U01      01     01\n",
      "    sample.timestamp         X         Y         Z subject gesture sample\n",
      "10             110.0 -1.991976 -8.887277  7.201759     U08      20     20\n",
      "11             121.0 -0.459687 -2.911349  9.500193     U08      20     20\n",
      "12             132.0  0.459687  4.137181  9.346964     U08      20     20\n",
      "13             143.0 -1.991976  4.750096  7.508216     U08      20     20\n",
      "14             154.0 -5.056554  3.371036  8.274362     U08      20     20\n",
      "15             165.0 -4.443638  1.991976  9.040505     U08      20     20\n",
      "16             176.0 -4.137181  2.145205  8.887277     U08      20     20\n",
      "17             187.0 -5.056554  1.838747  7.508216     U08      20     20\n",
      "18             198.0 -4.290410  1.225831  9.346964     U08      20     20\n",
      "19             209.0 -4.903325  2.451663  8.887277     U08      20     20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "scaler = StandardScaler()\r\n",
    "dataset_scaled = None\r\n",
    "\r\n",
    "for i, gesture in enumerate(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20']):\r\n",
    "    for j, subject in enumerate(['U01', 'U02', 'U03', 'U04', 'U05', 'U06', 'U07', 'U08']):\r\n",
    "        for k, sample in enumerate(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20']):\r\n",
    "                    \r\n",
    "            df = dataset[dataset['gesture']==gesture]\r\n",
    "            df = df[df['subject']==subject]\r\n",
    "            df = df[df['sample']==sample]\r\n",
    "            df.sort_values(by=['sample.timestamp'])\r\n",
    "\r\n",
    "            sc = scaler\r\n",
    "            sc = sc.fit_transform(df[[\"X\", \"Y\", \"Z\"]])\r\n",
    "            sc = pd.DataFrame(data=sc, columns=[\"X\", \"Y\", \"Z\"])\r\n",
    "            df[\"X\"] = sc[\"X\"]\r\n",
    "            df[\"Y\"] = sc[\"Y\"]\r\n",
    "            df[\"Z\"] = sc[\"Z\"]\r\n",
    "            #df[\"magnitude\"] = sc.apply(lambda row: magnitude(row['X'], row['Y'], row['Z']), axis=1)\r\n",
    "            if dataset_scaled is None:\r\n",
    "                dataset_scaled = df.copy()\r\n",
    "            else:\r\n",
    "                dataset_scaled = pd.concat([dataset_scaled, df])\r\n",
    "                \r\n",
    "#print(dataset_scaled)\r\n",
    "data = dataset_scaled\r\n",
    "print(dataset_scaled.head(10))\r\n",
    "print(dataset_scaled.tail(10))\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   sample.timestamp         X         Y         Z subject gesture sample\n",
      "0               0.0  0.046662  0.178172  0.383203     U01      01     01\n",
      "1              11.0 -0.243681  0.178172  0.139347     U01      01     01\n",
      "2              22.0  0.191834  0.455329  1.358630     U01      01     01\n",
      "3              33.0  2.079060  1.730249  1.602485     U01      01     01\n",
      "4              44.0  2.369403  1.065073 -1.079937     U01      01     01\n",
      "5              55.0  0.627347 -2.371668 -1.079937     U01      01     01\n",
      "6              66.0 -0.388851 -1.872786 -1.567648     U01      01     01\n",
      "7              77.0 -0.679194 -0.265279 -0.348367     U01      01     01\n",
      "8              88.0 -0.751780 -0.098985 -0.348367     U01      01     01\n",
      "9              99.0 -0.534023  0.399897  0.139347     U01      01     01\n",
      "    sample.timestamp         X         Y         Z subject gesture sample\n",
      "10             110.0 -0.487195 -1.474219 -1.639716     U08      20     20\n",
      "11             121.0 -0.109525 -0.296052  0.435874     U08      20     20\n",
      "12             132.0  0.117078  1.093581  0.297502     U08      20     20\n",
      "13             143.0 -0.487195  1.214418 -1.362972     U08      20     20\n",
      "14             154.0 -1.242536  0.942534 -0.671107     U08      20     20\n",
      "15             165.0 -1.091468  0.670649  0.020755     U08      20     20\n",
      "16             176.0 -1.015934  0.700858 -0.117617     U08      20     20\n",
      "17             187.0 -1.242536  0.640440 -1.362972     U08      20     20\n",
      "18             198.0 -1.053701  0.519602  0.297502     U08      20     20\n",
      "19             209.0 -1.204769  0.761277 -0.117617     U08      20     20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "dataset_cleaned = None\r\n",
    "dataset_outliers = None\r\n",
    "\r\n",
    "for i, gesture in enumerate(data['gesture'].unique()):\r\n",
    "    df_gesture = data[data['gesture']==gesture]\r\n",
    "    for j, subject in enumerate(df_gesture['subject'].unique()):\r\n",
    "        df_subject = df_gesture[df_gesture['subject']==subject]\r\n",
    "        \r\n",
    "        time_mean = df_subject.groupby([\"gesture\",\"subject\", \"sample\"]).count().groupby([\"gesture\",\"subject\"]).agg({'sample.timestamp': ['mean']})\r\n",
    "        time_std = df_subject.groupby([\"gesture\",\"subject\", \"sample\"]).count().groupby([\"gesture\",\"subject\"]).agg({'sample.timestamp': ['std']})\r\n",
    "        time_max = time_mean['sample.timestamp'].iloc[0]['mean'] + 1.0 * time_std['sample.timestamp'].iloc[0]['std']\r\n",
    "        #print(time_max)\r\n",
    "        time_min = time_mean['sample.timestamp'].iloc[0]['mean'] - 1.0 * time_std['sample.timestamp'].iloc[0]['std']\r\n",
    "        #print(time_min)\r\n",
    "        for i, sample in enumerate(df_subject['sample'].unique()):\r\n",
    "            df_sample = df_subject[df_subject['sample']==sample]\r\n",
    "            df_sample_count = df_sample.count()['sample.timestamp']\r\n",
    "            #print(df_sample_count)\r\n",
    "            if df_sample_count < time_min or df_sample_count > time_max:\r\n",
    "                if dataset_outliers is None:\r\n",
    "                    dataset_outliers = df_sample.copy()\r\n",
    "                else:\r\n",
    "                    dataset_outliers = pd.concat([dataset_outliers, df_sample])\r\n",
    "                #Delete same from training set\r\n",
    "                df_subject = df_subject[df_subject['sample'] != sample]\r\n",
    "                \r\n",
    "        if dataset_cleaned is None:\r\n",
    "            dataset_cleaned = df_subject.copy()\r\n",
    "        else:\r\n",
    "            dataset_cleaned = pd.concat([dataset_cleaned, df_subject])\r\n",
    "\r\n",
    "data = dataset_cleaned\r\n",
    "print(dataset_cleaned.head(10))\r\n",
    "print(dataset_cleaned.tail(10))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   sample.timestamp         X         Y         Z subject gesture sample\n",
      "0               0.0  0.046662  0.178172  0.383203     U01      01     01\n",
      "1              11.0 -0.243681  0.178172  0.139347     U01      01     01\n",
      "2              22.0  0.191834  0.455329  1.358630     U01      01     01\n",
      "3              33.0  2.079060  1.730249  1.602485     U01      01     01\n",
      "4              44.0  2.369403  1.065073 -1.079937     U01      01     01\n",
      "5              55.0  0.627347 -2.371668 -1.079937     U01      01     01\n",
      "6              66.0 -0.388851 -1.872786 -1.567648     U01      01     01\n",
      "7              77.0 -0.679194 -0.265279 -0.348367     U01      01     01\n",
      "8              88.0 -0.751780 -0.098985 -0.348367     U01      01     01\n",
      "9              99.0 -0.534023  0.399897  0.139347     U01      01     01\n",
      "    sample.timestamp         X         Y         Z subject gesture sample\n",
      "10             110.0 -0.487195 -1.474219 -1.639716     U08      20     20\n",
      "11             121.0 -0.109525 -0.296052  0.435874     U08      20     20\n",
      "12             132.0  0.117078  1.093581  0.297502     U08      20     20\n",
      "13             143.0 -0.487195  1.214418 -1.362972     U08      20     20\n",
      "14             154.0 -1.242536  0.942534 -0.671107     U08      20     20\n",
      "15             165.0 -1.091468  0.670649  0.020755     U08      20     20\n",
      "16             176.0 -1.015934  0.700858 -0.117617     U08      20     20\n",
      "17             187.0 -1.242536  0.640440 -1.362972     U08      20     20\n",
      "18             198.0 -1.053701  0.519602  0.297502     U08      20     20\n",
      "19             209.0 -1.204769  0.761277 -0.117617     U08      20     20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "dataset_timecut = None\r\n",
    "\r\n",
    "for i, gesture in enumerate(data['gesture'].unique()):\r\n",
    "    df_gesture = data[data['gesture']==gesture]\r\n",
    "    for j, subject in enumerate(df_gesture['subject'].unique()):\r\n",
    "        df_subject = df_gesture[df_gesture['subject']==subject] \r\n",
    "        time_max = 19 # 18 * 11 = 198\r\n",
    "        for i, sample in enumerate(df_subject['sample'].unique()):\r\n",
    "            df_sample = df_subject[df_subject['sample']==sample]\r\n",
    "            df_sample_count = df_sample.count()['sample.timestamp']\r\n",
    "            #print(df_sample_count)\r\n",
    "            if df_sample_count >= time_max:\r\n",
    "                df_sample = df_sample[df_sample['sample.timestamp'] <= (11 * (time_max-1))]\r\n",
    "                df_sample_count = df_sample.count()['sample.timestamp']\r\n",
    "                #print(df_sample_count)\r\n",
    "            elif df_sample_count < time_max:\r\n",
    "                for tmp in range(df_sample_count * 11, (time_max) * 11, 11):\r\n",
    "                    df = pd.DataFrame([[tmp, 0.0, 0.0, 0.0, gesture, subject, sample]], columns=['sample.timestamp', 'X', 'Y', 'Z', 'gesture', 'subject', 'sample'])\r\n",
    "                    df_sample = df_sample.append(df, ignore_index=True)            \r\n",
    "            #print(df_sample)\r\n",
    "            df_sample_count = df_sample.count()['sample.timestamp']\r\n",
    "            #print(df_sample_count)\r\n",
    "            if df_sample_count != time_max:\r\n",
    "                continue\r\n",
    "            if dataset_timecut is None:\r\n",
    "                dataset_timecut = df_sample.copy()\r\n",
    "            else:\r\n",
    "                dataset_timecut = pd.concat([dataset_timecut, df_sample])\r\n",
    "\r\n",
    "data = dataset_timecut\r\n",
    "print(dataset_timecut.head(10))\r\n",
    "print(dataset_timecut.tail(10))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   sample.timestamp         X         Y         Z subject gesture sample\n",
      "0               0.0  0.046662  0.178172  0.383203     U01      01     01\n",
      "1              11.0 -0.243681  0.178172  0.139347     U01      01     01\n",
      "2              22.0  0.191834  0.455329  1.358630     U01      01     01\n",
      "3              33.0  2.079060  1.730249  1.602485     U01      01     01\n",
      "4              44.0  2.369403  1.065073 -1.079937     U01      01     01\n",
      "5              55.0  0.627347 -2.371668 -1.079937     U01      01     01\n",
      "6              66.0 -0.388851 -1.872786 -1.567648     U01      01     01\n",
      "7              77.0 -0.679194 -0.265279 -0.348367     U01      01     01\n",
      "8              88.0 -0.751780 -0.098985 -0.348367     U01      01     01\n",
      "9              99.0 -0.534023  0.399897  0.139347     U01      01     01\n",
      "    sample.timestamp         X         Y         Z subject gesture sample\n",
      "9               99.0 -0.487195 -1.927360  0.435874     U08      20     20\n",
      "10             110.0 -0.487195 -1.474219 -1.639716     U08      20     20\n",
      "11             121.0 -0.109525 -0.296052  0.435874     U08      20     20\n",
      "12             132.0  0.117078  1.093581  0.297502     U08      20     20\n",
      "13             143.0 -0.487195  1.214418 -1.362972     U08      20     20\n",
      "14             154.0 -1.242536  0.942534 -0.671107     U08      20     20\n",
      "15             165.0 -1.091468  0.670649  0.020755     U08      20     20\n",
      "16             176.0 -1.015934  0.700858 -0.117617     U08      20     20\n",
      "17             187.0 -1.242536  0.640440 -1.362972     U08      20     20\n",
      "18             198.0 -1.053701  0.519602  0.297502     U08      20     20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from keras.models import Sequential\r\n",
    "from keras.layers import Bidirectional\r\n",
    "from keras.layers import LSTM\r\n",
    "from keras.layers import Dense\r\n",
    "from keras.layers import Dropout\r\n",
    "from keras.optimizers import adam_v2\r\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
    "from sklearn.model_selection import StratifiedGroupKFold\r\n",
    "from sklearn.model_selection import cross_validate\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from keras.utils import np_utils\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "import numpy\r\n",
    "\r\n",
    "\r\n",
    "# fix random seed for reproducibility\r\n",
    "seed = 1000\r\n",
    "numpy.random.seed(seed)\r\n",
    "# create the dataset\r\n",
    "def get_dataset():\r\n",
    "    X_train = []\r\n",
    "    Y_train = []\r\n",
    "    groups = []\r\n",
    "    for i, gesture in enumerate(data['gesture'].unique()):\r\n",
    "        df_gesture = data[data['gesture']==gesture]\r\n",
    "        for j, subject in enumerate(df_gesture['subject'].unique()):\r\n",
    "            df_subject = df_gesture[df_gesture['subject']==subject]\r\n",
    "            for k, sample in enumerate(df_subject['sample'].unique()):\r\n",
    "                df_sample = df_subject[df_subject['sample']==sample]\r\n",
    "                accel_vector = []\r\n",
    "                for index, row in df_sample.sort_values(by='sample.timestamp').iterrows():\r\n",
    "                    accel_vector.append([row['X'],row['Y'],row['Z']])\r\n",
    "                accel_vector = np.asarray(accel_vector)\r\n",
    "                X_train.append(accel_vector)\r\n",
    "                Y_train.append(gesture)\r\n",
    "                groups.append(subject)\r\n",
    "    X_train = np.asarray(X_train)\r\n",
    "    Y_train = LabelEncoder().fit_transform(Y_train)\r\n",
    "    #print(Y_train)\r\n",
    "    return X_train, Y_train, groups\r\n",
    "\r\n",
    "# Function to create model, required for KerasClassifier\r\n",
    "def create_model(epochs=128, dropout_rate=0.8, units=128):\r\n",
    "    model = Sequential()\r\n",
    "    model.add(\r\n",
    "        Bidirectional(\r\n",
    "              LSTM(\r\n",
    "                units=units, \r\n",
    "                input_shape=[19, 3]\r\n",
    "            )\r\n",
    "        )\r\n",
    "    )\r\n",
    "    model.add(Dropout(rate=dropout_rate))\r\n",
    "    model.add(Dense(units=units, activation='relu'))\r\n",
    "    model.add(Dense(20, activation='softmax'))\r\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=adam_v2.Adam(learning_rate=0.001), metrics=['accuracy'])\r\n",
    "\r\n",
    "    return model\r\n",
    "\r\n",
    "model = KerasClassifier(build_fn=create_model, epochs=128, batch_size=19)\r\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=1000)\r\n",
    "\r\n",
    "# get the dataset\r\n",
    "X, y, g = get_dataset()\r\n",
    "cv = cv.split(X, y, g)\r\n",
    "\r\n",
    "results = cross_validate(model, X=X, y=y, groups=g, scoring=('accuracy'), cv=cv, verbose=1, return_train_score=True, return_estimator=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/128\n",
      "92/92 [==============================] - 9s 8ms/step - loss: 2.4010 - accuracy: 0.2086\n",
      "Epoch 2/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 1.4102 - accuracy: 0.4839\n",
      "Epoch 3/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.8968 - accuracy: 0.6724\n",
      "Epoch 4/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.6909 - accuracy: 0.7552\n",
      "Epoch 5/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.5679 - accuracy: 0.8086\n",
      "Epoch 6/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.4430 - accuracy: 0.8408\n",
      "Epoch 7/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.3940 - accuracy: 0.8557\n",
      "Epoch 8/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.3017 - accuracy: 0.8874\n",
      "Epoch 9/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.2465 - accuracy: 0.9109\n",
      "Epoch 10/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.2352 - accuracy: 0.9144\n",
      "Epoch 11/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.1825 - accuracy: 0.9431\n",
      "Epoch 12/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.1584 - accuracy: 0.9471\n",
      "Epoch 13/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.1746 - accuracy: 0.9471\n",
      "Epoch 14/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.1713 - accuracy: 0.9483\n",
      "Epoch 15/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.1303 - accuracy: 0.9580\n",
      "Epoch 16/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.1044 - accuracy: 0.9661\n",
      "Epoch 17/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0735 - accuracy: 0.9782\n",
      "Epoch 18/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0932 - accuracy: 0.9684\n",
      "Epoch 19/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0778 - accuracy: 0.9759\n",
      "Epoch 20/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.1048 - accuracy: 0.9632\n",
      "Epoch 21/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0938 - accuracy: 0.9707\n",
      "Epoch 22/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0682 - accuracy: 0.9862\n",
      "Epoch 23/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0606 - accuracy: 0.9879\n",
      "Epoch 24/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0647 - accuracy: 0.9799\n",
      "Epoch 25/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0569 - accuracy: 0.9851\n",
      "Epoch 26/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0611 - accuracy: 0.9839\n",
      "Epoch 27/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0423 - accuracy: 0.9879\n",
      "Epoch 28/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0522 - accuracy: 0.9833\n",
      "Epoch 29/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0767 - accuracy: 0.9770\n",
      "Epoch 30/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0586 - accuracy: 0.9833\n",
      "Epoch 31/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0627 - accuracy: 0.9816\n",
      "Epoch 32/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0418 - accuracy: 0.9885\n",
      "Epoch 33/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0580 - accuracy: 0.9856\n",
      "Epoch 34/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0475 - accuracy: 0.9856\n",
      "Epoch 35/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0508 - accuracy: 0.9816\n",
      "Epoch 36/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0476 - accuracy: 0.9845\n",
      "Epoch 37/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0349 - accuracy: 0.9925\n",
      "Epoch 38/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0307 - accuracy: 0.9902\n",
      "Epoch 39/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0197 - accuracy: 0.9937\n",
      "Epoch 40/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0136 - accuracy: 0.9971\n",
      "Epoch 41/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0124 - accuracy: 0.9966\n",
      "Epoch 42/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0370 - accuracy: 0.9908\n",
      "Epoch 43/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0391 - accuracy: 0.9862\n",
      "Epoch 44/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0434 - accuracy: 0.9856\n",
      "Epoch 45/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0350 - accuracy: 0.9897\n",
      "Epoch 46/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0729 - accuracy: 0.9759\n",
      "Epoch 47/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0589 - accuracy: 0.9816\n",
      "Epoch 48/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0396 - accuracy: 0.9902\n",
      "Epoch 49/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0212 - accuracy: 0.9943\n",
      "Epoch 50/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0142 - accuracy: 0.9954\n",
      "Epoch 51/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0165 - accuracy: 0.9943\n",
      "Epoch 52/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0136 - accuracy: 0.9971\n",
      "Epoch 53/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0176 - accuracy: 0.9948\n",
      "Epoch 54/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0448 - accuracy: 0.9920\n",
      "Epoch 55/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.1156 - accuracy: 0.9695\n",
      "Epoch 56/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0500 - accuracy: 0.9839\n",
      "Epoch 57/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0315 - accuracy: 0.9925\n",
      "Epoch 58/128\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0319 - accuracy: 0.9897\n",
      "Epoch 59/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0197 - accuracy: 0.9943\n",
      "Epoch 60/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0285 - accuracy: 0.9891\n",
      "Epoch 61/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0333 - accuracy: 0.9902\n",
      "Epoch 62/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0205 - accuracy: 0.9943\n",
      "Epoch 63/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0156 - accuracy: 0.9954\n",
      "Epoch 64/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0209 - accuracy: 0.9948\n",
      "Epoch 65/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0177 - accuracy: 0.9971\n",
      "Epoch 66/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0222 - accuracy: 0.9925\n",
      "Epoch 67/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0310 - accuracy: 0.9908\n",
      "Epoch 68/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0568 - accuracy: 0.9868\n",
      "Epoch 69/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0217 - accuracy: 0.9948\n",
      "Epoch 70/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0572 - accuracy: 0.9799\n",
      "Epoch 71/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0421 - accuracy: 0.9874\n",
      "Epoch 72/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0352 - accuracy: 0.9897\n",
      "Epoch 73/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0475 - accuracy: 0.9885\n",
      "Epoch 74/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0093 - accuracy: 0.9960\n",
      "Epoch 75/128\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 0.0131 - accuracy: 0.9971\n",
      "Epoch 76/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0083 - accuracy: 0.9966\n",
      "Epoch 77/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0078 - accuracy: 0.9971\n",
      "Epoch 78/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0190 - accuracy: 0.9954\n",
      "Epoch 79/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0171 - accuracy: 0.9954\n",
      "Epoch 80/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0123 - accuracy: 0.9971\n",
      "Epoch 81/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0188 - accuracy: 0.9937\n",
      "Epoch 82/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0176 - accuracy: 0.9920\n",
      "Epoch 83/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0581 - accuracy: 0.9862\n",
      "Epoch 84/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0431 - accuracy: 0.9902\n",
      "Epoch 85/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0317 - accuracy: 0.9931\n",
      "Epoch 86/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0186 - accuracy: 0.9948\n",
      "Epoch 87/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0328 - accuracy: 0.9920\n",
      "Epoch 88/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0378 - accuracy: 0.9902\n",
      "Epoch 89/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0418 - accuracy: 0.9885\n",
      "Epoch 90/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0143 - accuracy: 0.9960\n",
      "Epoch 91/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0201 - accuracy: 0.9948\n",
      "Epoch 92/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0134 - accuracy: 0.9954\n",
      "Epoch 93/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 94/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0238 - accuracy: 0.9920\n",
      "Epoch 95/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0281 - accuracy: 0.9925\n",
      "Epoch 96/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0189 - accuracy: 0.9954\n",
      "Epoch 97/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0539 - accuracy: 0.9914\n",
      "Epoch 98/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0158 - accuracy: 0.9966\n",
      "Epoch 99/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0239 - accuracy: 0.9948\n",
      "Epoch 100/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0096 - accuracy: 0.9977\n",
      "Epoch 101/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0186 - accuracy: 0.9948\n",
      "Epoch 102/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0121 - accuracy: 0.9966\n",
      "Epoch 103/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0119 - accuracy: 0.9966\n",
      "Epoch 104/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0084 - accuracy: 0.9971\n",
      "Epoch 105/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0091 - accuracy: 0.9960\n",
      "Epoch 106/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0105 - accuracy: 0.9977\n",
      "Epoch 107/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0155 - accuracy: 0.9937\n",
      "Epoch 108/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0143 - accuracy: 0.9948\n",
      "Epoch 109/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0113 - accuracy: 0.9971\n",
      "Epoch 110/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0267 - accuracy: 0.9954\n",
      "Epoch 111/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0075 - accuracy: 0.9989\n",
      "Epoch 112/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0207 - accuracy: 0.9954\n",
      "Epoch 113/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0207 - accuracy: 0.9943\n",
      "Epoch 114/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0677 - accuracy: 0.9782\n",
      "Epoch 115/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0338 - accuracy: 0.9879\n",
      "Epoch 116/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0828 - accuracy: 0.9833\n",
      "Epoch 117/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0185 - accuracy: 0.9943\n",
      "Epoch 118/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0173 - accuracy: 0.9948\n",
      "Epoch 119/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0102 - accuracy: 0.9971\n",
      "Epoch 120/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0154 - accuracy: 0.9960\n",
      "Epoch 121/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0136 - accuracy: 0.9960\n",
      "Epoch 122/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0081 - accuracy: 0.9971\n",
      "Epoch 123/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0050 - accuracy: 0.9989\n",
      "Epoch 124/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0053 - accuracy: 0.9989\n",
      "Epoch 125/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 126/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0046 - accuracy: 0.9983\n",
      "Epoch 127/128\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 0.0070 - accuracy: 0.9966\n",
      "Epoch 128/128\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.0073 - accuracy: 0.9983\n",
      "Epoch 1/128\n",
      "112/112 [==============================] - 3s 8ms/step - loss: 2.3520 - accuracy: 0.2331\n",
      "Epoch 2/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 1.2583 - accuracy: 0.5282\n",
      "Epoch 3/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.8010 - accuracy: 0.7114\n",
      "Epoch 4/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.6086 - accuracy: 0.7806\n",
      "Epoch 5/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4527 - accuracy: 0.8484\n",
      "Epoch 6/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3654 - accuracy: 0.8766\n",
      "Epoch 7/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2774 - accuracy: 0.9068\n",
      "Epoch 8/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.2321 - accuracy: 0.9327\n",
      "Epoch 9/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.2275 - accuracy: 0.9294\n",
      "Epoch 10/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1600 - accuracy: 0.9487\n",
      "Epoch 11/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1463 - accuracy: 0.9557\n",
      "Epoch 12/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1215 - accuracy: 0.9647\n",
      "Epoch 13/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1129 - accuracy: 0.9675\n",
      "Epoch 14/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0945 - accuracy: 0.9680\n",
      "Epoch 15/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0694 - accuracy: 0.9765\n",
      "Epoch 16/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0720 - accuracy: 0.9807\n",
      "Epoch 17/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1083 - accuracy: 0.9685\n",
      "Epoch 18/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0833 - accuracy: 0.9746\n",
      "Epoch 19/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0812 - accuracy: 0.9779\n",
      "Epoch 20/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0551 - accuracy: 0.9821\n",
      "Epoch 21/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0686 - accuracy: 0.9793\n",
      "Epoch 22/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0585 - accuracy: 0.9826\n",
      "Epoch 23/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0618 - accuracy: 0.9831\n",
      "Epoch 24/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0659 - accuracy: 0.9793\n",
      "Epoch 25/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0540 - accuracy: 0.9835\n",
      "Epoch 26/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0549 - accuracy: 0.9863\n",
      "Epoch 27/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0236 - accuracy: 0.9948\n",
      "Epoch 28/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0246 - accuracy: 0.9948\n",
      "Epoch 29/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0301 - accuracy: 0.9906\n",
      "Epoch 30/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0440 - accuracy: 0.9859\n",
      "Epoch 31/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0396 - accuracy: 0.9882\n",
      "Epoch 32/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9906\n",
      "Epoch 33/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0524 - accuracy: 0.9849\n",
      "Epoch 34/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0721 - accuracy: 0.9750\n",
      "Epoch 35/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0433 - accuracy: 0.9854\n",
      "Epoch 36/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0244 - accuracy: 0.9911\n",
      "Epoch 37/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0259 - accuracy: 0.9906\n",
      "Epoch 38/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0380 - accuracy: 0.9906\n",
      "Epoch 39/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0526 - accuracy: 0.9849\n",
      "Epoch 40/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0554 - accuracy: 0.9826\n",
      "Epoch 41/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0254 - accuracy: 0.9920\n",
      "Epoch 42/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0173 - accuracy: 0.9958\n",
      "Epoch 43/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0147 - accuracy: 0.9958\n",
      "Epoch 44/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0163 - accuracy: 0.9953\n",
      "Epoch 45/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0095 - accuracy: 0.9972\n",
      "Epoch 46/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0099 - accuracy: 0.9972\n",
      "Epoch 47/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0154 - accuracy: 0.9920\n",
      "Epoch 48/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0377 - accuracy: 0.9868\n",
      "Epoch 49/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0661 - accuracy: 0.9802\n",
      "Epoch 50/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0564 - accuracy: 0.9826\n",
      "Epoch 51/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0690 - accuracy: 0.9812\n",
      "Epoch 52/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0212 - accuracy: 0.9939\n",
      "Epoch 53/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0173 - accuracy: 0.9967\n",
      "Epoch 54/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9972\n",
      "Epoch 55/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0155 - accuracy: 0.9953\n",
      "Epoch 56/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0167 - accuracy: 0.9953\n",
      "Epoch 57/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0283 - accuracy: 0.9882\n",
      "Epoch 58/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0198 - accuracy: 0.9939\n",
      "Epoch 59/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0485 - accuracy: 0.9887\n",
      "Epoch 60/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0451 - accuracy: 0.9873\n",
      "Epoch 61/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0149 - accuracy: 0.9962\n",
      "Epoch 62/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0273 - accuracy: 0.9934\n",
      "Epoch 63/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0218 - accuracy: 0.9934\n",
      "Epoch 64/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0122 - accuracy: 0.9958\n",
      "Epoch 65/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0136 - accuracy: 0.9967\n",
      "Epoch 66/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0264 - accuracy: 0.9920\n",
      "Epoch 67/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0061 - accuracy: 0.9991\n",
      "Epoch 68/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0085 - accuracy: 0.9986\n",
      "Epoch 69/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 70/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0086 - accuracy: 0.9967\n",
      "Epoch 71/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0265 - accuracy: 0.9929\n",
      "Epoch 72/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0506 - accuracy: 0.9873\n",
      "Epoch 73/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0395 - accuracy: 0.9887\n",
      "Epoch 74/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0405 - accuracy: 0.9892\n",
      "Epoch 75/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0102 - accuracy: 0.9972\n",
      "Epoch 76/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0070 - accuracy: 0.9981\n",
      "Epoch 77/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0072 - accuracy: 0.9976\n",
      "Epoch 78/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0141 - accuracy: 0.9972\n",
      "Epoch 79/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0320 - accuracy: 0.9939\n",
      "Epoch 80/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0384 - accuracy: 0.9873\n",
      "Epoch 81/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0172 - accuracy: 0.9920\n",
      "Epoch 82/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0178 - accuracy: 0.9939\n",
      "Epoch 83/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0345 - accuracy: 0.9901\n",
      "Epoch 84/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0226 - accuracy: 0.9934\n",
      "Epoch 85/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0190 - accuracy: 0.9948\n",
      "Epoch 86/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0606 - accuracy: 0.9863\n",
      "Epoch 87/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0309 - accuracy: 0.9911\n",
      "Epoch 88/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0286 - accuracy: 0.9915\n",
      "Epoch 89/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0157 - accuracy: 0.9953\n",
      "Epoch 90/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0075 - accuracy: 0.9972\n",
      "Epoch 91/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0106 - accuracy: 0.9967\n",
      "Epoch 92/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0054 - accuracy: 0.9986\n",
      "Epoch 93/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 0.9986\n",
      "Epoch 94/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0100 - accuracy: 0.9986\n",
      "Epoch 95/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9995\n",
      "Epoch 96/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 97/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9991\n",
      "Epoch 98/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 99/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 100/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0081 - accuracy: 0.9976\n",
      "Epoch 101/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0210 - accuracy: 0.9944\n",
      "Epoch 102/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0154 - accuracy: 0.9944\n",
      "Epoch 103/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0222 - accuracy: 0.9948\n",
      "Epoch 104/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0252 - accuracy: 0.9953\n",
      "Epoch 105/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0512 - accuracy: 0.9863\n",
      "Epoch 106/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0490 - accuracy: 0.9882\n",
      "Epoch 107/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0393 - accuracy: 0.9882\n",
      "Epoch 108/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0188 - accuracy: 0.9944\n",
      "Epoch 109/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0159 - accuracy: 0.9958\n",
      "Epoch 110/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0088 - accuracy: 0.9972\n",
      "Epoch 111/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9981\n",
      "Epoch 112/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0191 - accuracy: 0.9972\n",
      "Epoch 113/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0107 - accuracy: 0.9948\n",
      "Epoch 114/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0235 - accuracy: 0.9920\n",
      "Epoch 115/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0149 - accuracy: 0.9939\n",
      "Epoch 116/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0295 - accuracy: 0.9925\n",
      "Epoch 117/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0080 - accuracy: 0.9986\n",
      "Epoch 118/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0080 - accuracy: 0.9972\n",
      "Epoch 119/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0091 - accuracy: 0.9967\n",
      "Epoch 120/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0061 - accuracy: 0.9986\n",
      "Epoch 121/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0074 - accuracy: 0.9972\n",
      "Epoch 122/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0065 - accuracy: 0.9976\n",
      "Epoch 123/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0096 - accuracy: 0.9976\n",
      "Epoch 124/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0078 - accuracy: 0.9986\n",
      "Epoch 125/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0047 - accuracy: 0.9995\n",
      "Epoch 126/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9991\n",
      "Epoch 127/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0023 - accuracy: 0.9986\n",
      "Epoch 128/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0228 - accuracy: 0.9953\n",
      "Epoch 1/128\n",
      "112/112 [==============================] - 3s 8ms/step - loss: 2.2933 - accuracy: 0.2441\n",
      "Epoch 2/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 1.2969 - accuracy: 0.5325\n",
      "Epoch 3/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.8138 - accuracy: 0.7059\n",
      "Epoch 4/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.5994 - accuracy: 0.7908\n",
      "Epoch 5/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4909 - accuracy: 0.8214\n",
      "Epoch 6/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3831 - accuracy: 0.8619\n",
      "Epoch 7/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2905 - accuracy: 0.8968\n",
      "Epoch 8/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2726 - accuracy: 0.9105\n",
      "Epoch 9/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1985 - accuracy: 0.9373\n",
      "Epoch 10/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1566 - accuracy: 0.9529\n",
      "Epoch 11/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1247 - accuracy: 0.9599\n",
      "Epoch 12/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1090 - accuracy: 0.9661\n",
      "Epoch 13/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1034 - accuracy: 0.9694\n",
      "Epoch 14/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1117 - accuracy: 0.9642\n",
      "Epoch 15/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0924 - accuracy: 0.9717\n",
      "Epoch 16/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1003 - accuracy: 0.9670\n",
      "Epoch 17/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0759 - accuracy: 0.9797\n",
      "Epoch 18/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0826 - accuracy: 0.9755\n",
      "Epoch 19/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0735 - accuracy: 0.9797\n",
      "Epoch 20/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0695 - accuracy: 0.9793\n",
      "Epoch 21/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0407 - accuracy: 0.9868\n",
      "Epoch 22/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0344 - accuracy: 0.9906\n",
      "Epoch 23/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0616 - accuracy: 0.9835\n",
      "Epoch 24/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0577 - accuracy: 0.9802\n",
      "Epoch 25/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0488 - accuracy: 0.9821\n",
      "Epoch 26/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0505 - accuracy: 0.9797\n",
      "Epoch 27/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0571 - accuracy: 0.9830\n",
      "Epoch 28/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0287 - accuracy: 0.9920\n",
      "Epoch 29/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0570 - accuracy: 0.9877\n",
      "Epoch 30/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0588 - accuracy: 0.9783\n",
      "Epoch 31/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0819 - accuracy: 0.9760\n",
      "Epoch 32/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0492 - accuracy: 0.9882\n",
      "Epoch 33/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0349 - accuracy: 0.9887\n",
      "Epoch 34/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0254 - accuracy: 0.9920\n",
      "Epoch 35/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0150 - accuracy: 0.9953\n",
      "Epoch 36/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0242 - accuracy: 0.9925\n",
      "Epoch 37/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0431 - accuracy: 0.9873\n",
      "Epoch 38/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0322 - accuracy: 0.9901\n",
      "Epoch 39/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0710 - accuracy: 0.9821\n",
      "Epoch 40/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0241 - accuracy: 0.9920\n",
      "Epoch 41/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0328 - accuracy: 0.9901\n",
      "Epoch 42/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0524 - accuracy: 0.9854\n",
      "Epoch 43/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0491 - accuracy: 0.9859\n",
      "Epoch 44/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0309 - accuracy: 0.9920\n",
      "Epoch 45/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0178 - accuracy: 0.9939\n",
      "Epoch 46/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0380 - accuracy: 0.9901\n",
      "Epoch 47/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0165 - accuracy: 0.9943\n",
      "Epoch 48/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0319 - accuracy: 0.9887\n",
      "Epoch 49/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0486 - accuracy: 0.9844\n",
      "Epoch 50/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0160 - accuracy: 0.9943\n",
      "Epoch 51/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0187 - accuracy: 0.9934\n",
      "Epoch 52/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0197 - accuracy: 0.9943\n",
      "Epoch 53/128\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.0127 - accuracy: 0.9953\n",
      "Epoch 54/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0195 - accuracy: 0.9929\n",
      "Epoch 55/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0190 - accuracy: 0.9920\n",
      "Epoch 56/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0193 - accuracy: 0.9934\n",
      "Epoch 57/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0277 - accuracy: 0.9934\n",
      "Epoch 58/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0177 - accuracy: 0.9953\n",
      "Epoch 59/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0129 - accuracy: 0.9962\n",
      "Epoch 60/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0117 - accuracy: 0.9972\n",
      "Epoch 61/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0989 - accuracy: 0.9764\n",
      "Epoch 62/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0933 - accuracy: 0.9689\n",
      "Epoch 63/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0467 - accuracy: 0.9892\n",
      "Epoch 64/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0546 - accuracy: 0.9882\n",
      "Epoch 65/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0244 - accuracy: 0.9925\n",
      "Epoch 66/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0140 - accuracy: 0.9962\n",
      "Epoch 67/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0120 - accuracy: 0.9972\n",
      "Epoch 68/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0082 - accuracy: 0.9981\n",
      "Epoch 69/128\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0118 - accuracy: 0.9962\n",
      "Epoch 70/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0082 - accuracy: 0.9972\n",
      "Epoch 71/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0084 - accuracy: 0.9967\n",
      "Epoch 72/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0071 - accuracy: 0.9976\n",
      "Epoch 73/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0064 - accuracy: 0.9981\n",
      "Epoch 74/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0041 - accuracy: 0.9991\n",
      "Epoch 75/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0114 - accuracy: 0.9962\n",
      "Epoch 76/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0122 - accuracy: 0.9962\n",
      "Epoch 77/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0110 - accuracy: 0.9962\n",
      "Epoch 78/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0522 - accuracy: 0.9854\n",
      "Epoch 79/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0283 - accuracy: 0.9925\n",
      "Epoch 80/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0193 - accuracy: 0.9934\n",
      "Epoch 81/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0394 - accuracy: 0.9863\n",
      "Epoch 82/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0409 - accuracy: 0.9859\n",
      "Epoch 83/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0453 - accuracy: 0.9849\n",
      "Epoch 84/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0094 - accuracy: 0.9962\n",
      "Epoch 85/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0133 - accuracy: 0.9962\n",
      "Epoch 86/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0108 - accuracy: 0.9958\n",
      "Epoch 87/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0083 - accuracy: 0.9976\n",
      "Epoch 88/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0133 - accuracy: 0.9943\n",
      "Epoch 89/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0277 - accuracy: 0.9925\n",
      "Epoch 90/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0135 - accuracy: 0.9962\n",
      "Epoch 91/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0384 - accuracy: 0.9892\n",
      "Epoch 92/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0317 - accuracy: 0.9915\n",
      "Epoch 93/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0194 - accuracy: 0.9925\n",
      "Epoch 94/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0241 - accuracy: 0.9929\n",
      "Epoch 95/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0464 - accuracy: 0.9882\n",
      "Epoch 96/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0157 - accuracy: 0.9948\n",
      "Epoch 97/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0161 - accuracy: 0.9967\n",
      "Epoch 98/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0074 - accuracy: 0.9972\n",
      "Epoch 99/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0071 - accuracy: 0.9981\n",
      "Epoch 100/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0106 - accuracy: 0.9967\n",
      "Epoch 101/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0085 - accuracy: 0.9976\n",
      "Epoch 102/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0049 - accuracy: 0.9991\n",
      "Epoch 103/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0059 - accuracy: 0.9986\n",
      "Epoch 104/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0085 - accuracy: 0.9972\n",
      "Epoch 105/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0174 - accuracy: 0.9962\n",
      "Epoch 106/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 107/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 108/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 109/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0033 - accuracy: 0.9991\n",
      "Epoch 110/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0218 - accuracy: 0.9948\n",
      "Epoch 111/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0167 - accuracy: 0.9939\n",
      "Epoch 112/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0353 - accuracy: 0.9910\n",
      "Epoch 113/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0274 - accuracy: 0.9910\n",
      "Epoch 114/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0142 - accuracy: 0.9948\n",
      "Epoch 115/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0476 - accuracy: 0.9892\n",
      "Epoch 116/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0536 - accuracy: 0.9868\n",
      "Epoch 117/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0100 - accuracy: 0.9962\n",
      "Epoch 118/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0649 - accuracy: 0.9859\n",
      "Epoch 119/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0166 - accuracy: 0.9939\n",
      "Epoch 120/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0112 - accuracy: 0.9967\n",
      "Epoch 121/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0034 - accuracy: 0.9995\n",
      "Epoch 122/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0087 - accuracy: 0.9981\n",
      "Epoch 123/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0134 - accuracy: 0.9953\n",
      "Epoch 124/128\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "Epoch 125/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 126/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0171 - accuracy: 0.9972\n",
      "Epoch 127/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0109 - accuracy: 0.9967\n",
      "Epoch 128/128\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0052 - accuracy: 0.9972\n",
      "Epoch 1/128\n",
      "96/96 [==============================] - 3s 9ms/step - loss: 2.4310 - accuracy: 0.1935\n",
      "Epoch 2/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4527 - accuracy: 0.4666\n",
      "Epoch 3/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.9890 - accuracy: 0.6324\n",
      "Epoch 4/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.7907 - accuracy: 0.7153\n",
      "Epoch 5/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.5985 - accuracy: 0.7894\n",
      "Epoch 6/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.5073 - accuracy: 0.8181\n",
      "Epoch 7/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.4347 - accuracy: 0.8546\n",
      "Epoch 8/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.3306 - accuracy: 0.8911\n",
      "Epoch 9/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.3230 - accuracy: 0.8900\n",
      "Epoch 10/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2223 - accuracy: 0.9414\n",
      "Epoch 11/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2493 - accuracy: 0.9187\n",
      "Epoch 12/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.1807 - accuracy: 0.9469\n",
      "Epoch 13/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1765 - accuracy: 0.9464\n",
      "Epoch 14/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.1484 - accuracy: 0.9525\n",
      "Epoch 15/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1503 - accuracy: 0.9569\n",
      "Epoch 16/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1247 - accuracy: 0.9613\n",
      "Epoch 17/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0919 - accuracy: 0.9746\n",
      "Epoch 18/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0807 - accuracy: 0.9707\n",
      "Epoch 19/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1047 - accuracy: 0.9652\n",
      "Epoch 20/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1196 - accuracy: 0.9608\n",
      "Epoch 21/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0809 - accuracy: 0.9784\n",
      "Epoch 22/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0532 - accuracy: 0.9873\n",
      "Epoch 23/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0451 - accuracy: 0.9884\n",
      "Epoch 24/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0631 - accuracy: 0.9807\n",
      "Epoch 25/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0506 - accuracy: 0.9845\n",
      "Epoch 26/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0479 - accuracy: 0.9878\n",
      "Epoch 27/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0554 - accuracy: 0.9807\n",
      "Epoch 28/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0781 - accuracy: 0.9740\n",
      "Epoch 29/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1238 - accuracy: 0.9630\n",
      "Epoch 30/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0715 - accuracy: 0.9757\n",
      "Epoch 31/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0410 - accuracy: 0.9851\n",
      "Epoch 32/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0430 - accuracy: 0.9845\n",
      "Epoch 33/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0543 - accuracy: 0.9834\n",
      "Epoch 34/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0533 - accuracy: 0.9867\n",
      "Epoch 35/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0371 - accuracy: 0.9889\n",
      "Epoch 36/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0500 - accuracy: 0.9829\n",
      "Epoch 37/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0367 - accuracy: 0.9884\n",
      "Epoch 38/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0292 - accuracy: 0.9906\n",
      "Epoch 39/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0494 - accuracy: 0.9884\n",
      "Epoch 40/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0323 - accuracy: 0.9900\n",
      "Epoch 41/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0456 - accuracy: 0.9867\n",
      "Epoch 42/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0406 - accuracy: 0.9867\n",
      "Epoch 43/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0637 - accuracy: 0.9779\n",
      "Epoch 44/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0279 - accuracy: 0.9917\n",
      "Epoch 45/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0161 - accuracy: 0.9972\n",
      "Epoch 46/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0173 - accuracy: 0.9956\n",
      "Epoch 47/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0155 - accuracy: 0.9972\n",
      "Epoch 48/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0368 - accuracy: 0.9873\n",
      "Epoch 49/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0196 - accuracy: 0.9939\n",
      "Epoch 50/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0487 - accuracy: 0.9851\n",
      "Epoch 51/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0524 - accuracy: 0.9834\n",
      "Epoch 52/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0361 - accuracy: 0.9873\n",
      "Epoch 53/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0545 - accuracy: 0.9856\n",
      "Epoch 54/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0264 - accuracy: 0.9934\n",
      "Epoch 55/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0250 - accuracy: 0.9895\n",
      "Epoch 56/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0167 - accuracy: 0.9950\n",
      "Epoch 57/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0162 - accuracy: 0.9961\n",
      "Epoch 58/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0082 - accuracy: 0.9978\n",
      "Epoch 59/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0126 - accuracy: 0.9961\n",
      "Epoch 60/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0387 - accuracy: 0.9912\n",
      "Epoch 61/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0431 - accuracy: 0.9873\n",
      "Epoch 62/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0235 - accuracy: 0.9939\n",
      "Epoch 63/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0434 - accuracy: 0.9856\n",
      "Epoch 64/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0388 - accuracy: 0.9884\n",
      "Epoch 65/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0387 - accuracy: 0.9884\n",
      "Epoch 66/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0264 - accuracy: 0.9934\n",
      "Epoch 67/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0590 - accuracy: 0.9873\n",
      "Epoch 68/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0758 - accuracy: 0.9784\n",
      "Epoch 69/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0231 - accuracy: 0.9912\n",
      "Epoch 70/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0253 - accuracy: 0.9950\n",
      "Epoch 71/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0145 - accuracy: 0.9972\n",
      "Epoch 72/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0211 - accuracy: 0.9950\n",
      "Epoch 73/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0114 - accuracy: 0.9972\n",
      "Epoch 74/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0110 - accuracy: 0.9967\n",
      "Epoch 75/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0087 - accuracy: 0.9972\n",
      "Epoch 76/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0086 - accuracy: 0.9978\n",
      "Epoch 77/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0072 - accuracy: 0.9983\n",
      "Epoch 78/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0103 - accuracy: 0.9967\n",
      "Epoch 79/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 80/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0079 - accuracy: 0.9989\n",
      "Epoch 81/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0117 - accuracy: 0.9967\n",
      "Epoch 82/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0151 - accuracy: 0.9956\n",
      "Epoch 83/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0580 - accuracy: 0.9873\n",
      "Epoch 84/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0629 - accuracy: 0.9823\n",
      "Epoch 85/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0270 - accuracy: 0.9917\n",
      "Epoch 86/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0338 - accuracy: 0.9889\n",
      "Epoch 87/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0318 - accuracy: 0.9928\n",
      "Epoch 88/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0218 - accuracy: 0.9928\n",
      "Epoch 89/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0364 - accuracy: 0.9923\n",
      "Epoch 90/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0541 - accuracy: 0.9818\n",
      "Epoch 91/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0322 - accuracy: 0.9900\n",
      "Epoch 92/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0228 - accuracy: 0.9928\n",
      "Epoch 93/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0141 - accuracy: 0.9950\n",
      "Epoch 94/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0117 - accuracy: 0.9956\n",
      "Epoch 95/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0099 - accuracy: 0.9967\n",
      "Epoch 96/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0093 - accuracy: 0.9961\n",
      "Epoch 97/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0462 - accuracy: 0.9895\n",
      "Epoch 98/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0530 - accuracy: 0.9851\n",
      "Epoch 99/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0434 - accuracy: 0.9884\n",
      "Epoch 100/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0114 - accuracy: 0.9972\n",
      "Epoch 101/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0095 - accuracy: 0.9983\n",
      "Epoch 102/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0092 - accuracy: 0.9972\n",
      "Epoch 103/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0094 - accuracy: 0.9967\n",
      "Epoch 104/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0101 - accuracy: 0.9972\n",
      "Epoch 105/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0077 - accuracy: 0.9978\n",
      "Epoch 106/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0216 - accuracy: 0.9923\n",
      "Epoch 107/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0112 - accuracy: 0.9967\n",
      "Epoch 108/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0118 - accuracy: 0.9967\n",
      "Epoch 109/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - accuracy: 0.9994\n",
      "Epoch 110/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0041 - accuracy: 0.9983\n",
      "Epoch 111/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - accuracy: 0.9989\n",
      "Epoch 112/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0076 - accuracy: 0.9989\n",
      "Epoch 113/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0081 - accuracy: 0.9978\n",
      "Epoch 114/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0077 - accuracy: 0.9978\n",
      "Epoch 115/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - accuracy: 0.9983\n",
      "Epoch 116/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 117/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0117 - accuracy: 0.9967\n",
      "Epoch 118/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0113 - accuracy: 0.9967\n",
      "Epoch 119/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - accuracy: 0.9972\n",
      "Epoch 120/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0053 - accuracy: 0.9983\n",
      "Epoch 121/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0066 - accuracy: 0.9978\n",
      "Epoch 122/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0295 - accuracy: 0.9939\n",
      "Epoch 123/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0643 - accuracy: 0.9884\n",
      "Epoch 124/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0400 - accuracy: 0.9867\n",
      "Epoch 125/128\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0089 - accuracy: 0.9978\n",
      "Epoch 126/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0107 - accuracy: 0.9950\n",
      "Epoch 127/128\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0179 - accuracy: 0.9934\n",
      "Epoch 128/128\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0174 - accuracy: 0.9967\n",
      "Epoch 1/128\n",
      "95/95 [==============================] - 3s 8ms/step - loss: 2.4301 - accuracy: 0.1801\n",
      "Epoch 2/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 1.5968 - accuracy: 0.4028\n",
      "Epoch 3/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 1.0999 - accuracy: 0.6006\n",
      "Epoch 4/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.7346 - accuracy: 0.7319\n",
      "Epoch 5/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.5494 - accuracy: 0.7994\n",
      "Epoch 6/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.4126 - accuracy: 0.8532\n",
      "Epoch 7/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.3389 - accuracy: 0.8859\n",
      "Epoch 8/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.3027 - accuracy: 0.8997\n",
      "Epoch 9/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.1969 - accuracy: 0.9424\n",
      "Epoch 10/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.1787 - accuracy: 0.9507\n",
      "Epoch 11/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.1505 - accuracy: 0.9562\n",
      "Epoch 12/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.1285 - accuracy: 0.9579\n",
      "Epoch 13/128\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 0.1337 - accuracy: 0.9496\n",
      "Epoch 14/128\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 0.1293 - accuracy: 0.9590\n",
      "Epoch 15/128\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 0.1018 - accuracy: 0.9657\n",
      "Epoch 16/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0662 - accuracy: 0.9823\n",
      "Epoch 17/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0673 - accuracy: 0.9817\n",
      "Epoch 18/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0538 - accuracy: 0.9839\n",
      "Epoch 19/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0617 - accuracy: 0.9812\n",
      "Epoch 20/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0491 - accuracy: 0.9850\n",
      "Epoch 21/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0602 - accuracy: 0.9801\n",
      "Epoch 22/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0684 - accuracy: 0.9778\n",
      "Epoch 23/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0839 - accuracy: 0.9751\n",
      "Epoch 24/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0654 - accuracy: 0.9795\n",
      "Epoch 25/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0809 - accuracy: 0.9773\n",
      "Epoch 26/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0702 - accuracy: 0.9778\n",
      "Epoch 27/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0504 - accuracy: 0.9823\n",
      "Epoch 28/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0336 - accuracy: 0.9889\n",
      "Epoch 29/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0430 - accuracy: 0.9878\n",
      "Epoch 30/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0437 - accuracy: 0.9861\n",
      "Epoch 31/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0309 - accuracy: 0.9889\n",
      "Epoch 32/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9906\n",
      "Epoch 33/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0686 - accuracy: 0.9795\n",
      "Epoch 34/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0383 - accuracy: 0.9884\n",
      "Epoch 35/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0271 - accuracy: 0.9906\n",
      "Epoch 36/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0115 - accuracy: 0.9978\n",
      "Epoch 37/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0083 - accuracy: 0.9983\n",
      "Epoch 38/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0173 - accuracy: 0.9945\n",
      "Epoch 39/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0560 - accuracy: 0.9861\n",
      "Epoch 40/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0226 - accuracy: 0.9922\n",
      "Epoch 41/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0440 - accuracy: 0.9878\n",
      "Epoch 42/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0422 - accuracy: 0.9839\n",
      "Epoch 43/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0161 - accuracy: 0.9961\n",
      "Epoch 44/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0256 - accuracy: 0.9928\n",
      "Epoch 45/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0175 - accuracy: 0.9967\n",
      "Epoch 46/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0289 - accuracy: 0.9906\n",
      "Epoch 47/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0198 - accuracy: 0.9939\n",
      "Epoch 48/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0309 - accuracy: 0.9917\n",
      "Epoch 49/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9906\n",
      "Epoch 50/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0355 - accuracy: 0.9900\n",
      "Epoch 51/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0497 - accuracy: 0.9856\n",
      "Epoch 52/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0556 - accuracy: 0.9817\n",
      "Epoch 53/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0421 - accuracy: 0.9889\n",
      "Epoch 54/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9906\n",
      "Epoch 55/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0114 - accuracy: 0.9972\n",
      "Epoch 56/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0137 - accuracy: 0.9950\n",
      "Epoch 57/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0084 - accuracy: 0.9972\n",
      "Epoch 58/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0106 - accuracy: 0.9967\n",
      "Epoch 59/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0082 - accuracy: 0.9972\n",
      "Epoch 60/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0068 - accuracy: 0.9972\n",
      "Epoch 61/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0224 - accuracy: 0.9922\n",
      "Epoch 62/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0430 - accuracy: 0.9900\n",
      "Epoch 63/128\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 0.0612 - accuracy: 0.9839\n",
      "Epoch 64/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0468 - accuracy: 0.9889\n",
      "Epoch 65/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0236 - accuracy: 0.9922\n",
      "Epoch 66/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0061 - accuracy: 0.9989\n",
      "Epoch 67/128\n",
      "95/95 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 0.9983\n",
      "Epoch 68/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 69/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 0.9994\n",
      "Epoch 70/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 71/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9989\n",
      "Epoch 72/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0166 - accuracy: 0.9967\n",
      "Epoch 73/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0211 - accuracy: 0.9950\n",
      "Epoch 74/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0573 - accuracy: 0.9845\n",
      "Epoch 75/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0249 - accuracy: 0.9895\n",
      "Epoch 76/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0390 - accuracy: 0.9889\n",
      "Epoch 77/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0111 - accuracy: 0.9956\n",
      "Epoch 78/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0193 - accuracy: 0.9950\n",
      "Epoch 79/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0522 - accuracy: 0.9839\n",
      "Epoch 80/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0169 - accuracy: 0.9939\n",
      "Epoch 81/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0070 - accuracy: 0.9978\n",
      "Epoch 82/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 83/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 84/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 85/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0070 - accuracy: 0.9989\n",
      "Epoch 86/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0157 - accuracy: 0.9950\n",
      "Epoch 87/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0157 - accuracy: 0.9950\n",
      "Epoch 88/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.9895\n",
      "Epoch 89/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.9895\n",
      "Epoch 90/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0200 - accuracy: 0.9961\n",
      "Epoch 91/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0119 - accuracy: 0.9967\n",
      "Epoch 92/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0155 - accuracy: 0.9950\n",
      "Epoch 93/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0186 - accuracy: 0.9939\n",
      "Epoch 94/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0364 - accuracy: 0.9928\n",
      "Epoch 95/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0258 - accuracy: 0.9922\n",
      "Epoch 96/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0133 - accuracy: 0.9972\n",
      "Epoch 97/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0055 - accuracy: 0.9978\n",
      "Epoch 98/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 99/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 100/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 101/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 102/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9989\n",
      "Epoch 103/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 104/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 105/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0053 - accuracy: 0.9983\n",
      "Epoch 106/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0268 - accuracy: 0.9956\n",
      "Epoch 107/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0261 - accuracy: 0.9922\n",
      "Epoch 108/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0455 - accuracy: 0.9878\n",
      "Epoch 109/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0847 - accuracy: 0.9812\n",
      "Epoch 110/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0256 - accuracy: 0.9922\n",
      "Epoch 111/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0106 - accuracy: 0.9956\n",
      "Epoch 112/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0114 - accuracy: 0.9961\n",
      "Epoch 113/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 114/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9989\n",
      "Epoch 115/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 116/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 0.9989\n",
      "Epoch 117/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 0.9989\n",
      "Epoch 118/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9928\n",
      "Epoch 119/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0346 - accuracy: 0.9911\n",
      "Epoch 120/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0402 - accuracy: 0.9884\n",
      "Epoch 121/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0489 - accuracy: 0.9911\n",
      "Epoch 122/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0118 - accuracy: 0.9956\n",
      "Epoch 123/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0178 - accuracy: 0.9961\n",
      "Epoch 124/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0165 - accuracy: 0.9950\n",
      "Epoch 125/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0058 - accuracy: 0.9978\n",
      "Epoch 126/128\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.0179 - accuracy: 0.9922\n",
      "Epoch 127/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0047 - accuracy: 0.9989\n",
      "Epoch 128/128\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.0119 - accuracy: 0.9967\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  8.8min finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(results)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'fit_time': array([100.9526999 , 112.05299973, 119.66807127, 101.80736375,\n",
      "        92.74166822]), 'score_time': array([0.45850015, 0.44400072, 0.58249784, 0.43350029, 0.6674974 ]), 'estimator': [<keras.wrappers.scikit_learn.KerasClassifier object at 0x000001E4054F5040>, <keras.wrappers.scikit_learn.KerasClassifier object at 0x000001E4054F50A0>, <keras.wrappers.scikit_learn.KerasClassifier object at 0x000001E4054F5130>, <keras.wrappers.scikit_learn.KerasClassifier object at 0x000001E4054F51F0>, <keras.wrappers.scikit_learn.KerasClassifier object at 0x000001E4054BFE80>], 'test_score': array([0.95909091, 0.85144928, 0.97841727, 0.92047377, 0.93445378]), 'train_score': array([0.99770115, 0.99952919, 0.99952875, 0.99944721, 1.        ])}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "data = dataset_outliers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "dataset_timecut = None\r\n",
    "\r\n",
    "for i, gesture in enumerate(data['gesture'].unique()):\r\n",
    "    df_gesture = data[data['gesture']==gesture]\r\n",
    "    for j, subject in enumerate(df_gesture['subject'].unique()):\r\n",
    "        df_subject = df_gesture[df_gesture['subject']==subject] \r\n",
    "        time_max = 19 # 18 * 11 = 198\r\n",
    "        for i, sample in enumerate(df_subject['sample'].unique()):\r\n",
    "            df_sample = df_subject[df_subject['sample']==sample]\r\n",
    "            df_sample_count = df_sample.count()['sample.timestamp']\r\n",
    "            #print(df_sample_count)\r\n",
    "            if df_sample_count >= time_max:\r\n",
    "                df_sample = df_sample[df_sample['sample.timestamp'] <= (11 * (time_max-1))]\r\n",
    "                df_sample_count = df_sample.count()['sample.timestamp']\r\n",
    "                #print(df_sample_count)\r\n",
    "            elif df_sample_count < time_max:\r\n",
    "                for tmp in range(df_sample_count * 11, (time_max) * 11, 11):\r\n",
    "                    df = pd.DataFrame([[tmp, 0.0, 0.0, 0.0, gesture, subject, sample]], columns=['sample.timestamp', 'X', 'Y', 'Z', 'gesture', 'subject', 'sample'])\r\n",
    "                    df_sample = df_sample.append(df, ignore_index=True)            \r\n",
    "            #print(df_sample)\r\n",
    "            df_sample_count = df_sample.count()['sample.timestamp']\r\n",
    "            #print(df_sample_count)\r\n",
    "            if df_sample_count != time_max:\r\n",
    "                continue\r\n",
    "            if dataset_timecut is None:\r\n",
    "                dataset_timecut = df_sample.copy()\r\n",
    "            else:\r\n",
    "                dataset_timecut = pd.concat([dataset_timecut, df_sample])\r\n",
    "\r\n",
    "data = dataset_timecut\r\n",
    "print(dataset_timecut.head(10))\r\n",
    "print(dataset_timecut.tail(10))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   sample.timestamp         X         Y         Z subject gesture sample\n",
      "0               0.0  0.476846  0.311937  0.992948     U01      01     07\n",
      "1              11.0  0.315910  0.607456  0.046727     U01      01     07\n",
      "2              22.0  1.844796  1.198494  0.677541     U01      01     07\n",
      "3              33.0  2.569006  2.380571  0.362134     U01      01     07\n",
      "4              44.0  2.488538  1.050734  0.992948     U01      01     07\n",
      "5              55.0  2.005732 -2.717134 -0.899493     U01      01     07\n",
      "6              66.0 -0.247364 -2.421615 -3.422747     U01      01     07\n",
      "7              77.0 -1.052040 -0.352981 -0.899493     U01      01     07\n",
      "8              88.0 -0.649702  0.016418  0.677541     U01      01     07\n",
      "9              99.0 -0.649702  0.311937  0.362134     U01      01     07\n",
      "    sample.timestamp         X         Y         Z subject gesture sample\n",
      "9               99.0  0.101073  0.354159  0.170351     U08      20     18\n",
      "10             110.0 -0.020215  1.151017 -1.822746     U08      20     18\n",
      "11             121.0 -0.586221  0.818993 -1.516116     U08      20     18\n",
      "12             132.0 -0.747937  0.586576 -0.442910     U08      20     18\n",
      "13             143.0 -1.030940  0.520171 -0.136281     U08      20     18\n",
      "14             154.0 -1.030940  0.453766 -0.442910     U08      20     18\n",
      "15             165.0 -0.909653  0.420564  0.017036     U08      20     18\n",
      "16             176.0 -1.152227  0.586576 -0.136281     U08      20     18\n",
      "17             187.0 -0.909653  0.686183 -0.136281     U08      20     18\n",
      "18             198.0  0.000000  0.000000  0.000000     U08      20     18\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# fix random seed for reproducibility\r\n",
    "seed = 1000\r\n",
    "numpy.random.seed(seed)\r\n",
    "# create the dataset\r\n",
    "def get_dataset():\r\n",
    "    X_train = []\r\n",
    "    Y_train = []\r\n",
    "    groups = []\r\n",
    "    for i, gesture in enumerate(data['gesture'].unique()):\r\n",
    "        df_gesture = data[data['gesture']==gesture]\r\n",
    "        for j, subject in enumerate(df_gesture['subject'].unique()):\r\n",
    "            df_subject = df_gesture[df_gesture['subject']==subject]\r\n",
    "            for k, sample in enumerate(df_subject['sample'].unique()):\r\n",
    "                df_sample = df_subject[df_subject['sample']==sample]\r\n",
    "                accel_vector = []\r\n",
    "                for index, row in df_sample.sort_values(by='sample.timestamp').iterrows():\r\n",
    "                    accel_vector.append([row['X'],row['Y'],row['Z']])\r\n",
    "                accel_vector = np.asarray(accel_vector)\r\n",
    "                X_train.append(accel_vector)\r\n",
    "                Y_train.append(gesture)\r\n",
    "                groups.append(subject)\r\n",
    "    X_train = np.asarray(X_train)\r\n",
    "    Y_train = LabelEncoder().fit_transform(Y_train)\r\n",
    "    #print(Y_train)\r\n",
    "    return X_train, Y_train, groups\r\n",
    "\r\n",
    "X_test, y_test, g = get_dataset()\r\n",
    "y_predicted = []\r\n",
    "y_predicted.append(results['estimator'][0].predict(X_test))\r\n",
    "y_predicted.append(results['estimator'][1].predict(X_test))\r\n",
    "y_predicted.append(results['estimator'][2].predict(X_test))\r\n",
    "y_predicted.append(results['estimator'][3].predict(X_test))\r\n",
    "y_predicted.append(results['estimator'][4].predict(X_test))\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\r\n",
    "#Print Classification Report\r\n",
    "print('Classification Report')\r\n",
    "print(classification_report(y_test, y_predicted[0]))\r\n",
    "\r\n",
    "print('Classification Report')\r\n",
    "print(classification_report(y_test, y_predicted[1]))\r\n",
    "\r\n",
    "print('Classification Report')\r\n",
    "print(classification_report(y_test, y_predicted[2]))\r\n",
    "\r\n",
    "print('Classification Report')\r\n",
    "print(classification_report(y_test, y_predicted[3]))\r\n",
    "\r\n",
    "print('Classification Report')\r\n",
    "print(classification_report(y_test, y_predicted[4]))\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        39\n",
      "           1       0.97      0.94      0.96        34\n",
      "           2       0.97      0.93      0.95        41\n",
      "           3       1.00      0.95      0.97        38\n",
      "           4       0.96      1.00      0.98        43\n",
      "           5       0.96      1.00      0.98        48\n",
      "           6       1.00      0.88      0.94        41\n",
      "           7       1.00      0.95      0.98        42\n",
      "           8       0.94      0.97      0.95        32\n",
      "           9       0.93      1.00      0.96        38\n",
      "          10       0.95      0.98      0.96        42\n",
      "          11       1.00      1.00      1.00        39\n",
      "          12       0.93      1.00      0.96        26\n",
      "          13       1.00      0.93      0.96        41\n",
      "          14       0.95      0.95      0.95        44\n",
      "          15       0.96      0.98      0.97        44\n",
      "          16       1.00      1.00      1.00        44\n",
      "          17       0.90      0.93      0.91        28\n",
      "          18       0.92      1.00      0.96        47\n",
      "          19       0.95      0.89      0.92        45\n",
      "\n",
      "    accuracy                           0.96       796\n",
      "   macro avg       0.96      0.96      0.96       796\n",
      "weighted avg       0.96      0.96      0.96       796\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        39\n",
      "           1       1.00      0.88      0.94        34\n",
      "           2       1.00      0.88      0.94        41\n",
      "           3       0.95      0.95      0.95        38\n",
      "           4       1.00      0.98      0.99        43\n",
      "           5       1.00      1.00      1.00        48\n",
      "           6       1.00      0.95      0.97        41\n",
      "           7       0.98      1.00      0.99        42\n",
      "           8       0.97      0.94      0.95        32\n",
      "           9       0.93      1.00      0.96        38\n",
      "          10       0.97      0.81      0.88        42\n",
      "          11       0.95      0.97      0.96        39\n",
      "          12       1.00      0.85      0.92        26\n",
      "          13       0.98      1.00      0.99        41\n",
      "          14       0.98      1.00      0.99        44\n",
      "          15       0.98      1.00      0.99        44\n",
      "          16       0.95      0.95      0.95        44\n",
      "          17       0.77      0.96      0.86        28\n",
      "          18       0.89      1.00      0.94        47\n",
      "          19       0.94      0.98      0.96        45\n",
      "\n",
      "    accuracy                           0.96       796\n",
      "   macro avg       0.96      0.95      0.95       796\n",
      "weighted avg       0.96      0.96      0.96       796\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        39\n",
      "           1       0.97      0.97      0.97        34\n",
      "           2       1.00      0.93      0.96        41\n",
      "           3       1.00      0.95      0.97        38\n",
      "           4       1.00      1.00      1.00        43\n",
      "           5       1.00      1.00      1.00        48\n",
      "           6       1.00      0.88      0.94        41\n",
      "           7       1.00      0.98      0.99        42\n",
      "           8       1.00      0.97      0.98        32\n",
      "           9       0.93      1.00      0.96        38\n",
      "          10       0.95      1.00      0.98        42\n",
      "          11       0.97      1.00      0.99        39\n",
      "          12       1.00      0.92      0.96        26\n",
      "          13       0.93      1.00      0.96        41\n",
      "          14       0.92      1.00      0.96        44\n",
      "          15       0.96      0.98      0.97        44\n",
      "          16       0.98      1.00      0.99        44\n",
      "          17       1.00      0.93      0.96        28\n",
      "          18       0.90      0.98      0.94        47\n",
      "          19       0.93      0.89      0.91        45\n",
      "\n",
      "    accuracy                           0.97       796\n",
      "   macro avg       0.97      0.97      0.97       796\n",
      "weighted avg       0.97      0.97      0.97       796\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        39\n",
      "           1       0.97      0.94      0.96        34\n",
      "           2       0.90      0.90      0.90        41\n",
      "           3       0.97      0.95      0.96        38\n",
      "           4       1.00      1.00      1.00        43\n",
      "           5       0.91      1.00      0.95        48\n",
      "           6       1.00      0.85      0.92        41\n",
      "           7       0.98      0.98      0.98        42\n",
      "           8       0.91      1.00      0.96        32\n",
      "           9       0.95      1.00      0.97        38\n",
      "          10       0.91      1.00      0.95        42\n",
      "          11       1.00      1.00      1.00        39\n",
      "          12       0.90      1.00      0.95        26\n",
      "          13       1.00      1.00      1.00        41\n",
      "          14       0.82      0.75      0.79        44\n",
      "          15       0.88      0.84      0.86        44\n",
      "          16       1.00      0.95      0.98        44\n",
      "          17       0.96      0.93      0.95        28\n",
      "          18       0.82      1.00      0.90        47\n",
      "          19       0.94      0.73      0.83        45\n",
      "\n",
      "    accuracy                           0.94       796\n",
      "   macro avg       0.94      0.94      0.94       796\n",
      "weighted avg       0.94      0.94      0.94       796\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        39\n",
      "           1       1.00      0.97      0.99        34\n",
      "           2       0.93      0.90      0.91        41\n",
      "           3       0.88      0.97      0.93        38\n",
      "           4       0.91      1.00      0.96        43\n",
      "           5       1.00      1.00      1.00        48\n",
      "           6       1.00      0.88      0.94        41\n",
      "           7       0.98      1.00      0.99        42\n",
      "           8       1.00      0.97      0.98        32\n",
      "           9       0.97      1.00      0.99        38\n",
      "          10       0.93      1.00      0.97        42\n",
      "          11       0.97      1.00      0.99        39\n",
      "          12       0.96      1.00      0.98        26\n",
      "          13       0.98      1.00      0.99        41\n",
      "          14       0.96      1.00      0.98        44\n",
      "          15       0.95      0.91      0.93        44\n",
      "          16       1.00      0.98      0.99        44\n",
      "          17       0.95      0.75      0.84        28\n",
      "          18       0.94      0.98      0.96        47\n",
      "          19       0.98      0.93      0.95        45\n",
      "\n",
      "    accuracy                           0.96       796\n",
      "   macro avg       0.96      0.96      0.96       796\n",
      "weighted avg       0.96      0.96      0.96       796\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "c1ba51e39e6bd29053b7e2b4655472941cff3bf937946d7f7ef2ac3167d24754"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}