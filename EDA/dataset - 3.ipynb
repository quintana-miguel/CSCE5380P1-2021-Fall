{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c32b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def magnitude(X, Y, Z):\n",
    "    return math.sqrt(float(X**2) + float(Y**2) + float(Z**2))\n",
    "\n",
    "\n",
    "path = 'gestures-dataset'\n",
    "\n",
    "dataset = None\n",
    "\n",
    "for subject in os.listdir(path):\n",
    "    if os.path.isfile(os.path.join(path, subject)):\n",
    "        continue\n",
    "    if subject in ('U01', 'U02', 'U03', 'U04', 'U05', 'U06', 'U07', 'U08'):\n",
    "        for gesture in os.listdir(os.path.join(path, subject)):\n",
    "            if os.path.isfile(os.path.join(path, subject, gesture)):\n",
    "                continue\n",
    "            gesture = str(gesture)\n",
    "            for samplefile in os.listdir(os.path.join(path, subject, gesture)):\n",
    "                if os.path.isfile(os.path.join(path, subject, gesture, samplefile)):\n",
    "                    df = pd.read_csv(os.path.join(path, subject, gesture, samplefile), \\\n",
    "                        sep = ' ', \\\n",
    "                        names = ['System.currentTimeMillis()', \\\n",
    "                        'System.nanoTime()', \\\n",
    "                        'sample.timestamp', \\\n",
    "                        'X', \\\n",
    "                        'Y', \\\n",
    "                        'Z' \\\n",
    "                        ])\n",
    "                    df = df[[\"sample.timestamp\", \"X\", \"Y\", \"Z\"]]\n",
    "                                        \n",
    "                    start = df[\"sample.timestamp\"][0]\n",
    "                    df[\"sample.timestamp\"] -= start\n",
    "                    df[\"sample.timestamp\"] /= 10000000\n",
    "                    df[\"subject\"] = subject\n",
    "                    df[\"gesture\"] = gesture\n",
    "                    df[\"sample\"] = str(samplefile[:-4])\n",
    "                    #print(df)\n",
    "                    if dataset is None:\n",
    "                        dataset = df.copy()\n",
    "                    else:\n",
    "                        dataset = pd.concat([dataset, df])\n",
    "\n",
    "dataset = dataset.sort_values(by=['gesture','subject','sample','sample.timestamp'])\n",
    "#print(dataset)\n",
    "print(dataset.head(10))\n",
    "print(dataset.tail(10))\n",
    "\n",
    "                    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9484b228-7a0d-45f6-90df-8a4f27b176bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "gdf = dataset.groupby([\"gesture\",\"subject\", \"sample\"]).count().groupby([\"gesture\",\"subject\"]).agg({'sample.timestamp': ['mean', 'std', 'min', 'max']})\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11741455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dataset_scaled = None\n",
    "\n",
    "for i, gesture in enumerate(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20']):\n",
    "    for j, subject in enumerate(['U01', 'U02', 'U03', 'U04', 'U05', 'U06', 'U07', 'U08']):\n",
    "        for k, sample in enumerate(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20']):\n",
    "                    \n",
    "            df = dataset[dataset['gesture']==gesture]\n",
    "            df = df[df['subject']==subject]\n",
    "            df = df[df['sample']==sample]\n",
    "            df.sort_values(by=['sample.timestamp'])\n",
    "\n",
    "            sc = scaler\n",
    "            sc = sc.fit_transform(df[[\"X\", \"Y\", \"Z\"]])\n",
    "            sc = pd.DataFrame(data=sc, columns=[\"X\", \"Y\", \"Z\"])\n",
    "            df[\"X\"] = sc[\"X\"]\n",
    "            df[\"Y\"] = sc[\"Y\"]\n",
    "            df[\"Z\"] = sc[\"Z\"]\n",
    "            #df[\"magnitude\"] = sc.apply(lambda row: magnitude(row['X'], row['Y'], row['Z']), axis=1)\n",
    "            if dataset_scaled is None:\n",
    "                dataset_scaled = df.copy()\n",
    "            else:\n",
    "                dataset_scaled = pd.concat([dataset_scaled, df])\n",
    "                \n",
    "#print(dataset_scaled)\n",
    "print(dataset_scaled.head(10))\n",
    "print(dataset_scaled.tail(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb1d15-29bd-4f50-b7ef-4b7dce787344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i, gesture in enumerate(dataset_scaled['gesture'].unique()):\n",
    "    df_gesture = dataset_scaled[dataset_scaled['gesture']==gesture]\n",
    "    f, axes = plt.subplots(8, 3, figsize=(50,150), sharex=\"row\", sharey=\"row\")\n",
    "    for j, subject in enumerate(df_gesture['subject'].unique()):\n",
    "        df_subject = df_gesture[df_gesture['subject']==subject]\n",
    "                \n",
    "        time_max = df_subject.groupby([\"gesture\",\"subject\", \"sample\"]).count().groupby([\"gesture\",\"subject\"]).agg({'sample.timestamp': ['max']})\n",
    "        #print(time_max)\n",
    "        time_max = time_max['sample.timestamp'].iloc[0]['max']\n",
    "\n",
    "        \n",
    "        time_scale = []\n",
    "        for tmp in range(0, time_max * 11, 11):\n",
    "            time_scale.append(tmp)\n",
    "        #print(time_scale)\n",
    "        dictionary = {'time' : pd.Series(time_scale)}\n",
    "        for i, sample in enumerate(df_subject['sample'].unique()):\n",
    "            dictionary[str(sample)] = df_subject[df_subject['sample']==sample]['X']\n",
    "            #print(dictionary[str(sample)].size)\n",
    "            if dictionary[str(sample)].count() < time_max:\n",
    "                tmp = []\n",
    "                for i in range((dictionary[str(sample)].count() - 1) * 11, time_max - 1 * 11, 11):\n",
    "                    tmp.append(0.0)\n",
    "                tmp = pd.Series(tmp,dtype=np.float64)\n",
    "                dictionary[str(sample)] = dictionary[str(sample)].append(tmp, ignore_index=True)\n",
    "            #print(dictionary[str(sample)].size)\n",
    "        #print(dictionary)\n",
    "        data_preproc = pd.DataFrame(dictionary)\n",
    "        sns.lineplot(x='time', y='value', hue='variable', data=pd.melt(data_preproc, ['time']),ax=axes[j,0])\n",
    "        dictionary = {'time' : pd.Series(time_scale)}\n",
    "        for i, sample in enumerate(df_subject['sample'].unique()):\n",
    "            dictionary[str(sample)] = df_subject[df_subject['sample']==sample]['Y']\n",
    "            #print(dictionary[str(sample)].size)\n",
    "            if dictionary[str(sample)].count() < time_max:\n",
    "                tmp = []\n",
    "                for i in range((dictionary[str(sample)].count() - 1) * 11, time_max - 1 * 11, 11):\n",
    "                    tmp.append(0.0)\n",
    "                tmp = pd.Series(tmp,dtype=np.float64)\n",
    "                dictionary[str(sample)] = dictionary[str(sample)].append(tmp, ignore_index=True)\n",
    "            #print(dictionary[str(sample)].size)\n",
    "        #print(dictionary)\n",
    "        data_preproc = pd.DataFrame(dictionary)\n",
    "        sns.lineplot(x='time', y='value', hue='variable', data=pd.melt(data_preproc, ['time']),ax=axes[j,1])\n",
    "        dictionary = {'time' : pd.Series(time_scale)}\n",
    "        for i, sample in enumerate(df_subject['sample'].unique()):\n",
    "            dictionary[str(sample)] = df_subject[df_subject['sample']==sample]['Z']\n",
    "            #print(dictionary[str(sample)].size)\n",
    "            if dictionary[str(sample)].count() < time_max:\n",
    "                tmp = []\n",
    "                for i in range((dictionary[str(sample)].count() - 1) * 11, time_max - 1 * 11, 11):\n",
    "                    tmp.append(0.0)\n",
    "                tmp = pd.Series(tmp,dtype=np.float64)\n",
    "                dictionary[str(sample)] = dictionary[str(sample)].append(tmp, ignore_index=True)\n",
    "            #print(dictionary[str(sample)].size)\n",
    "        #print(dictionary)\n",
    "        data_preproc = pd.DataFrame(dictionary)\n",
    "        sns.lineplot(x='time', y='value', hue='variable', data=pd.melt(data_preproc, ['time']),ax=axes[j,2])\n",
    "        #plt.legend(bbox_to_anchor=(1.01, 1), borderaxespad=0)        \n",
    "    plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c235ab-e5ae-44df-9ebb-0757f2b48f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset_cleaned = None\n",
    "\n",
    "for i, gesture in enumerate(dataset_scaled['gesture'].unique()):\n",
    "    df_gesture = dataset_scaled[dataset_scaled['gesture']==gesture]\n",
    "    for j, subject in enumerate(df_gesture['subject'].unique()):\n",
    "        df_subject = df_gesture[df_gesture['subject']==subject]\n",
    "        \n",
    "        time_mean = df_subject.groupby([\"gesture\",\"subject\", \"sample\"]).count().groupby([\"gesture\",\"subject\"]).agg({'sample.timestamp': ['mean']})\n",
    "        time_std = df_subject.groupby([\"gesture\",\"subject\", \"sample\"]).count().groupby([\"gesture\",\"subject\"]).agg({'sample.timestamp': ['std']})\n",
    "        time_max = time_mean['sample.timestamp'].iloc[0]['mean'] + 1.0 * time_std['sample.timestamp'].iloc[0]['std']\n",
    "        #print(time_max)\n",
    "        time_min = time_mean['sample.timestamp'].iloc[0]['mean'] - 1.0 * time_std['sample.timestamp'].iloc[0]['std']\n",
    "        #print(time_min)\n",
    "        for i, sample in enumerate(df_subject['sample'].unique()):\n",
    "            df_sample_count = df_subject[df_subject['sample']==sample].count()['sample.timestamp']\n",
    "            #print(df_sample_count)\n",
    "            if df_sample_count < time_min or df_sample_count > time_max:\n",
    "                df_subject = df_subject[df_subject['sample'] != sample]\n",
    "                \n",
    "        if dataset_cleaned is None:\n",
    "            dataset_cleaned = df_subject.copy()\n",
    "        else:\n",
    "            dataset_cleaned = pd.concat([dataset_cleaned, df_subject])\n",
    "\n",
    "print(dataset_cleaned.head(10))\n",
    "print(dataset_cleaned.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eb78e1-b0e9-49e9-acfa-875b3fcc25d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "gdf = dataset_cleaned.groupby([\"gesture\",\"subject\", \"sample\"]).count().groupby([\"gesture\",\"subject\"]).agg({'sample.timestamp': ['mean', 'std', 'min', 'max']})\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a57d180-fed0-4ad6-b958-ecdfd2faa948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i, gesture in enumerate(dataset_cleaned['gesture'].unique()):\n",
    "    df_gesture = dataset_cleaned[dataset_cleaned['gesture']==gesture]\n",
    "    f, axes = plt.subplots(8, 3, figsize=(50,150), sharex=\"all\", sharey=\"all\")\n",
    "    for j, subject in enumerate(df_gesture['subject'].unique()):\n",
    "        df_subject = df_gesture[df_gesture['subject']==subject]\n",
    "        \n",
    "        time_max = df_subject.groupby([\"gesture\",\"subject\", \"sample\"]).count().groupby([\"gesture\",\"subject\"]).agg({'sample.timestamp': ['max']})\n",
    "        #print(time_max)\n",
    "        time_max = time_max['sample.timestamp'].iloc[0]['max']\n",
    "        \n",
    "        time_scale = []\n",
    "        for tmp in range(0, time_max * 11, 11):\n",
    "            time_scale.append(tmp)\n",
    "        #print(time_scale)\n",
    "        dictionary = {'time' : pd.Series(time_scale)}\n",
    "        for i, sample in enumerate(df_subject['sample'].unique()):\n",
    "            dictionary[str(sample)] = df_subject[df_subject['sample']==sample]['X']\n",
    "            #print(dictionary[str(sample)].size)\n",
    "            if dictionary[str(sample)].size < time_max:\n",
    "                tmp = []\n",
    "                for i in range((dictionary[str(sample)].size - 1) * 11, time_max - 1 * 11, 11):\n",
    "                    tmp.append(0.0)\n",
    "                tmp = pd.Series(tmp,dtype=np.float64)\n",
    "                dictionary[str(sample)] = dictionary[str(sample)].append(tmp, ignore_index=True)\n",
    "            #print(dictionary[str(sample)].size)\n",
    "        #print(dictionary)\n",
    "        data_preproc = pd.DataFrame(dictionary)\n",
    "        sns.lineplot(x='time', y='value', hue='variable', data=pd.melt(data_preproc, ['time']),ax=axes[j,0])\n",
    "        dictionary = {'time' : pd.Series(time_scale)}\n",
    "        for i, sample in enumerate(df_subject['sample'].unique()):\n",
    "            dictionary[str(sample)] = df_subject[df_subject['sample']==sample]['Y']\n",
    "            #print(dictionary[str(sample)].size)\n",
    "            if dictionary[str(sample)].size < time_max:\n",
    "                tmp = []\n",
    "                for i in range((dictionary[str(sample)].size - 1) * 11, time_max - 1 * 11, 11):\n",
    "                    tmp.append(0.0)\n",
    "                tmp = pd.Series(tmp,dtype=np.float64)\n",
    "                dictionary[str(sample)] = dictionary[str(sample)].append(tmp, ignore_index=True)\n",
    "            #print(dictionary[str(sample)].size)\n",
    "        #print(dictionary)\n",
    "        data_preproc = pd.DataFrame(dictionary)\n",
    "        sns.lineplot(x='time', y='value', hue='variable', data=pd.melt(data_preproc, ['time']),ax=axes[j,1])\n",
    "        dictionary = {'time' : pd.Series(time_scale)}\n",
    "        for i, sample in enumerate(df_subject['sample'].unique()):\n",
    "            dictionary[str(sample)] = df_subject[df_subject['sample']==sample]['Z']\n",
    "            #print(dictionary[str(sample)].size)\n",
    "            if dictionary[str(sample)].size < time_max:\n",
    "                tmp = []\n",
    "                for i in range((dictionary[str(sample)].size - 1) * 11, time_max - 1 * 11, 11):\n",
    "                    tmp.append(0.0)\n",
    "                tmp = pd.Series(tmp,dtype=np.float64)\n",
    "                dictionary[str(sample)] = dictionary[str(sample)].append(tmp, ignore_index=True)\n",
    "            #print(dictionary[str(sample)].size)\n",
    "        #print(dictionary)\n",
    "        data_preproc = pd.DataFrame(dictionary)\n",
    "        sns.lineplot(x='time', y='value', hue='variable', data=pd.melt(data_preproc, ['time']),ax=axes[j,2])\n",
    "        #plt.legend(bbox_to_anchor=(1.01, 1), borderaxespad=0)        \n",
    "    plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c2ef4b-69e8-42a8-8a52-4e33c9831930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset_timecut = None\n",
    "\n",
    "for i, gesture in enumerate(dataset_cleaned['gesture'].unique()):\n",
    "    df_gesture = dataset_cleaned[dataset_cleaned['gesture']==gesture]\n",
    "    for j, subject in enumerate(df_gesture['subject'].unique()):\n",
    "        df_subject = df_gesture[df_gesture['subject']==subject] \n",
    "        time_max = 19 # 18 * 11 = 198\n",
    "        for i, sample in enumerate(df_subject['sample'].unique()):\n",
    "            df_sample = df_subject[df_subject['sample']==sample]\n",
    "            df_sample_count = df_sample.count()['sample.timestamp']\n",
    "            #print(df_sample_count)\n",
    "            if df_sample_count >= time_max:\n",
    "                df_sample = df_sample[df_sample['sample.timestamp'] <= (11 * (time_max-1))]\n",
    "                df_sample_count = df_sample.count()['sample.timestamp']\n",
    "                #print(df_sample_count)\n",
    "            elif df_sample_count < time_max:\n",
    "                for tmp in range(df_sample_count * 11, (time_max) * 11, 11):\n",
    "                    df = pd.DataFrame([[tmp, 0.0, 0.0, 0.0, gesture, subject, sample]], columns=['sample.timestamp', 'X', 'Y', 'Z', 'gesture', 'subject', 'sample'])\n",
    "                    df_sample = df_sample.append(df, ignore_index=True)            \n",
    "            #print(df_sample)\n",
    "            df_sample_count = df_sample.count()['sample.timestamp']\n",
    "            #print(df_sample_count)\n",
    "            if df_sample_count != time_max:\n",
    "                continue\n",
    "            if dataset_timecut is None:\n",
    "                dataset_timecut = df_sample.copy()\n",
    "            else:\n",
    "                dataset_timecut = pd.concat([dataset_timecut, df_sample])\n",
    "\n",
    "print(dataset_timecut.head(10))\n",
    "print(dataset_timecut.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f15a2-529d-4181-9e29-1cb369569150",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "gdf = dataset_timecut.groupby([\"gesture\",\"subject\", \"sample\"]).count().groupby([\"gesture\",\"subject\"]).agg({'sample.timestamp': ['mean', 'std', 'min', 'max']})\n",
    "gdf\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f11283-b88f-471f-b551-0ae0f36866a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i, gesture in enumerate(dataset_timecut['gesture'].unique()):\n",
    "    df_gesture = dataset_timecut[dataset_timecut['gesture']==gesture]\n",
    "    f, axes = plt.subplots(8, 3, figsize=(50,150), sharex=\"all\", sharey=\"all\")\n",
    "    for j, subject in enumerate(df_gesture['subject'].unique()):\n",
    "        df_subject = df_gesture[df_gesture['subject']==subject]\n",
    "                        \n",
    "        time_max = df_subject.groupby([\"gesture\",\"subject\", \"sample\"]).count().groupby([\"gesture\",\"subject\"]).agg({'sample.timestamp': ['max']})\n",
    "        #print(time_max)\n",
    "        time_max = time_max['sample.timestamp'].iloc[0]['max']\n",
    "\n",
    "        time_scale = []\n",
    "        for tmp in range(0, time_max * 11, 11):\n",
    "            time_scale.append(tmp)\n",
    "\n",
    "        dictionary = {'time' : pd.Series(time_scale)}\n",
    "        for k, sample in enumerate(df_subject['sample'].unique()):\n",
    "            dictionary[str(sample)] = df_subject[df_subject['sample']==sample]['X']\n",
    "        data_preproc = pd.DataFrame(dictionary)\n",
    "        data=pd.melt(data_preproc, ['time'])\n",
    "        sns.lineplot(x='time', y='value', hue='variable', data=data, ax=axes[j,0])\n",
    "\n",
    "        dictionary = {'time' : pd.Series(time_scale)}\n",
    "        for k, sample in enumerate(df_subject['sample'].unique()):\n",
    "            dictionary[str(sample)] = df_subject[df_subject['sample']==sample]['Y']\n",
    "        data_preproc = pd.DataFrame(dictionary)\n",
    "        data=pd.melt(data_preproc, ['time'])\n",
    "        sns.lineplot(x='time', y='value', hue='variable', data=data, ax=axes[j,1])\n",
    "\n",
    "        dictionary = {'time' : pd.Series(time_scale)}\n",
    "        for k, sample in enumerate(df_subject['sample'].unique()):\n",
    "            dictionary[str(sample)] = df_subject[df_subject['sample']==sample]['Z']\n",
    "        data_preproc = pd.DataFrame(dictionary)\n",
    "        data=pd.melt(data_preproc, ['time'])\n",
    "        sns.lineplot(x='time', y='value', hue='variable', data=data, ax=axes[j,2])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51af9172-6584-47ec-874a-d440c34c1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "sns.countplot(x = 'subject',\n",
    "              data = dataset_timecut,\n",
    "              palette=[sns.color_palette()[0]]\n",
    "              );\n",
    "plt.title(\"Records per subject\");\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.countplot(x = 'gesture',\n",
    "              data = dataset_timecut,\n",
    "              palette=[sns.color_palette()[0]]\n",
    "              );\n",
    "plt.title(\"Records per gesture\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caaeebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "features_sample = None\n",
    "\n",
    "for i, gesture in enumerate(dataset_timecut['gesture'].unique()):\n",
    "    df_gesture = dataset_timecut[dataset_timecut['gesture']==gesture]\n",
    "    for j, subject in enumerate(df_gesture['subject'].unique()):\n",
    "        df_subject = df_gesture[df_gesture['subject']==subject]\n",
    "        for k, sample in enumerate(df_subject['sample'].unique()):\n",
    "            df_sample = df_subject[df_subject['sample']==sample]\n",
    "            df_sample.sort_values(by=['sample.timestamp'])\n",
    "\n",
    "            df_feature = pd.DataFrame(columns = [\"gesture\",\"subject\", \"sample\"])\n",
    "            df_feature = df_feature.append({'gesture' :gesture, 'subject' : subject, 'sample' : sample, \\\n",
    "                                        'meanx': df_sample[\"X\"].mean(), 'meany': df_sample[\"Y\"].mean(), 'meanz': df_sample[\"Z\"].mean(), \\\n",
    "                                        'stdx': df_sample[\"X\"].std(), 'stdy': df_sample[\"Y\"].std(), 'stdz': df_sample[\"Z\"].std(), \\\n",
    "                                        'madx': df_sample[\"X\"].mad(), 'mady': df_sample[\"Y\"].mad(), 'madz': df_sample[\"Z\"].mad(), \\\n",
    "                                        'semx': df_sample[\"X\"].sem(), 'semy': df_sample[\"Y\"].sem(), 'semz': df_sample[\"Z\"].sem(), \\\n",
    "                                        'kurtx': df_sample[\"X\"].kurt(), 'kurty': df_sample[\"Y\"].kurt(), 'kurtz': df_sample[\"Z\"].kurt(), \\\n",
    "                                        'skewx': df_sample[\"X\"].skew(), 'skewy': df_sample[\"Y\"].skew(), 'skewz': df_sample[\"Z\"].skew(), \\\n",
    "                                        'corr9x': df_sample[\"X\"].autocorr(9), 'corr9y': df_sample[\"Y\"].autocorr(9), 'corr9z': df_sample[\"Z\"].autocorr(9), \\\n",
    "                                        'corr6x': df_sample[\"X\"].autocorr(6), 'corr9y': df_sample[\"Y\"].autocorr(6), 'corr9z': df_sample[\"Z\"].autocorr(6), \\\n",
    "                                        'corr3x': df_sample[\"X\"].autocorr(3), 'corr9y': df_sample[\"Y\"].autocorr(3), 'corr9z': df_sample[\"Z\"].autocorr(3), \\\n",
    "                                        'corr2x': df_sample[\"X\"].autocorr(2), 'corr9y': df_sample[\"Y\"].autocorr(2), 'corr9z': df_sample[\"Z\"].autocorr(2), \\\n",
    "                                       }, \\\n",
    "                                       ignore_index=True)\n",
    "            if features_sample is None:\n",
    "                features_sample = df_feature.copy()\n",
    "            else:\n",
    "                features_sample = pd.concat([features_sample, df_feature], ignore_index=True)\n",
    "\n",
    "print(features_sample.head(10))\n",
    "print(features_sample.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0435b1-c432-4941-9d0b-e937e02dd136",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22192/594769480.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;31m# evaluate model using each test condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mcv_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mideal_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mideal_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# check for invalid results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22192/594769480.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(cv, model)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# get the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22192/594769480.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# create the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"gesture\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"subject\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sample\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gesture\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"subject\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features_sample' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from numpy import mean\n",
    "from numpy import isnan\n",
    "from numpy import asarray\n",
    "from numpy import polyfit\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import pyplot\n",
    "import sklearn \n",
    "#print(sklearn.__version__)\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "# create the dataset\n",
    "def get_dataset():\n",
    "    X = features_sample.copy().drop(labels = [\"gesture\",\"subject\", \"sample\"], axis = 1).to_numpy()\n",
    "    y = features_sample.copy()[\"gesture\"].to_list()\n",
    "    g = features_sample.copy()[\"subject\"].to_list()\n",
    "    return X, y, g\n",
    " \n",
    "# retrieve the model to be evaluate\n",
    "def get_model():\n",
    "\tmodel = LogisticRegression()\n",
    "\treturn model\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(LogisticRegression(penalty=\"l2\",max_iter=100000,solver=\"sag\"))\n",
    "\tmodels.append(RidgeClassifier(max_iter=100000, solver=\"sag\"))\n",
    "\tmodels.append(SGDClassifier(max_iter=100000))\n",
    "\tmodels.append(PassiveAggressiveClassifier(max_iter=100000))\n",
    "\tmodels.append(KNeighborsClassifier(n_neighbors=5))\n",
    "\tmodels.append(DecisionTreeClassifier())\n",
    "\tmodels.append(ExtraTreeClassifier())\n",
    "\tmodels.append(LinearSVC(max_iter=100000))\n",
    "\tmodels.append(SVC())\n",
    "\tmodels.append(GaussianNB())\n",
    "\tmodels.append(AdaBoostClassifier())\n",
    "\tmodels.append(BaggingClassifier())\n",
    "\tmodels.append(RandomForestClassifier())\n",
    "\tmodels.append(ExtraTreesClassifier())\n",
    "\tmodels.append(GaussianProcessClassifier(max_iter_predict=10000))\n",
    "\tmodels.append(GradientBoostingClassifier())\n",
    "\tmodels.append(LinearDiscriminantAnalysis())\n",
    "\tmodels.append(QuadraticDiscriminantAnalysis())\n",
    "\treturn models\n",
    " \n",
    "# evaluate the model using a given test condition\n",
    "def evaluate_model(cv, model):\n",
    "    # get the dataset\n",
    "    X, y, g = get_dataset()\n",
    "    cv = cv.split(X, y, g)\n",
    "    # evaluate the model\n",
    "    scores = cross_val_score(model, X, y, groups=g, scoring='accuracy', cv=cv, n_jobs=8, verbose=0)\n",
    "    # return scores\n",
    "    return mean(scores)\n",
    "\n",
    "# define test conditions\n",
    "ideal_cv = LeaveOneOut()\n",
    "# define folds to test\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=1000)\n",
    "# get the list of models to consider\n",
    "models = get_models()\n",
    "# collect results\n",
    "ideal_results, cv_results = list(), list()\n",
    "# evaluate each model\n",
    "for model in models:\n",
    "    # evaluate model using each test condition\n",
    "    cv_mean = evaluate_model(cv, model)\n",
    "    ideal_mean = evaluate_model(ideal_cv, model)\n",
    "\t# check for invalid results\n",
    "    if isnan(cv_mean) or isnan(ideal_mean):\n",
    "        continue\n",
    "\t# store results\n",
    "    cv_results.append(cv_mean)\n",
    "    ideal_results.append(ideal_mean)\n",
    "\t# summarize progress\n",
    "    print('>%s: ideal=%.3f, cv=%.3f' % (type(model).__name__, ideal_mean, cv_mean))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# calculate the correlation between each test condition\n",
    "corr, _ = pearsonr(cv_results, ideal_results)\n",
    "print('Correlation: %.3f' % corr)\n",
    "# scatter plot of results\n",
    "pyplot.scatter(cv_results, ideal_results)\n",
    "# plot the line of best fit\n",
    "coeff, bias = polyfit(cv_results, ideal_results, 1)\n",
    "line = coeff * asarray(cv_results) + bias\n",
    "pyplot.plot(cv_results, line, color='r')\n",
    "# label the plot\n",
    "pyplot.title('5-fold CV vs LOOCV Mean Accuracy')\n",
    "pyplot.xlabel('Mean Accuracy (10-fold CV)')\n",
    "pyplot.ylabel('Mean Accuracy (LOOCV)')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f48e640-7eef-483e-8c73-8163ce470e76",
   "metadata": {},
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "\n",
    "work = features_event.copy()\n",
    "targets = pd.DataFrame(work[[\"gesture\",\"subject\",\"event\"]], columns=[\"gesture\",\"subject\",\"event\"])\n",
    "targets.reset_index(inplace=True, drop=True)\n",
    "work = work.drop(labels = [\"gesture\",\"subject\", \"event\"], axis = 1)\n",
    "\n",
    "#pca = PCA(n_components=3)\n",
    "pca = PCA(.95)\n",
    "principalComponents = pca.fit_transform(work)\n",
    "#print(principalComponents[0])\n",
    "#print(pca.explained_variance_ratio_)\n",
    "#total = 0\n",
    "#for tmp in pca.explained_variance_ratio_:\n",
    "#    total += tmp\n",
    "#print(total)\n",
    "print(pca.n_features_)\n",
    "print(pca.n_samples_)\n",
    "#print(pca.noise_variance_)\n",
    "print(pca.n_components_)\n",
    "#print(pca.components_)\n",
    "columns = []\n",
    "for i in range(pca.n_components_):\n",
    "    columns.append(\"principal component \"+str(i+1))\n",
    "#print(columns)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = columns)\n",
    "finalDf = pd.concat([principalDf, targets], axis = 1)\n",
    "#print(finalDf)\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "fig = plt.figure(figsize = (70,70))\n",
    "i = 0\n",
    "for i in range(pca.n_components_):\n",
    "    j = 0\n",
    "    for j in range(pca.n_components_):\n",
    "    \n",
    "        ax = fig.add_subplot(pca.n_components_,pca.n_components_,pca.n_components_*i+j+1) \n",
    "        ax.set_xlabel('Principal Component ' + str(i + 1), fontsize = 15)\n",
    "        ax.set_ylabel('Principal Component ' + str(j + 1), fontsize = 15)\n",
    "        ax.set_title(str(i + 1) + 'x' + str(j + 1) + ' Component PCA', fontsize = 20)\n",
    "\n",
    "\n",
    "        targets = finalDf['gesture'].unique()\n",
    "        #colors = range(20)\n",
    "        colors = cm.rainbow(np.linspace(0, 1, targets.size))\n",
    "        #print(colors)\n",
    "        for target, color in zip(targets,colors):\n",
    "            indicesToKeep = finalDf['gesture'] == target\n",
    "            colorarray = []\n",
    "            for row in indicesToKeep.iteritems():\n",
    "                if row[1] == True:\n",
    "                    colorarray.append(color)\n",
    "            ax.scatter( finalDf.loc[indicesToKeep, 'principal component '+ str(i + 1)]\n",
    "                        , finalDf.loc[indicesToKeep, 'principal component '+ str(j + 1)]\n",
    "                        , c = colorarray\n",
    "                        #, cmap='Accent'\n",
    "                        , s = 50)\n",
    "            ax.legend(targets)\n",
    "            ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd9092c-c3c9-4da2-a50c-a1cc405bf4d7",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from numpy import mean\n",
    "from numpy import isnan\n",
    "from numpy import asarray\n",
    "from numpy import polyfit\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# create the dataset\n",
    "def get_dataset():\n",
    "    X = finalDf.copy().drop(labels = [\"gesture\",\"subject\", \"event\"], axis = 1).to_numpy()\n",
    "    y = finalDf.copy()[\"gesture\"].to_list()\n",
    "    return X, y\n",
    " \n",
    "# retrieve the model to be evaluate\n",
    "def get_model():\n",
    "\tmodel = LogisticRegression()\n",
    "\treturn model\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(LogisticRegression(penalty=\"l2\",max_iter=100000,solver=\"sag\"))\n",
    "\tmodels.append(RidgeClassifier(copy_X=True, max_iter=100000, solver=\"sag\"))\n",
    "\tmodels.append(SGDClassifier(max_iter=100000))\n",
    "\tmodels.append(PassiveAggressiveClassifier(max_iter=100000))\n",
    "\tmodels.append(KNeighborsClassifier(n_neighbors=5))\n",
    "\tmodels.append(DecisionTreeClassifier())\n",
    "\tmodels.append(ExtraTreeClassifier())\n",
    "\tmodels.append(LinearSVC(max_iter=100000))\n",
    "\tmodels.append(SVC())\n",
    "#\tmodels.append(GaussianNB())\n",
    "#\tmodels.append(AdaBoostClassifier())\n",
    "#\tmodels.append(BaggingClassifier())\n",
    "\tmodels.append(RandomForestClassifier())\n",
    "\tmodels.append(ExtraTreesClassifier())\n",
    "#\tmodels.append(GaussianProcessClassifier(max_iter_predict=10000))\n",
    "#\tmodels.append(GradientBoostingClassifier())\n",
    "#\tmodels.append(LinearDiscriminantAnalysis())\n",
    "#\tmodels.append(QuadraticDiscriminantAnalysis())\n",
    "\treturn models\n",
    " \n",
    "# evaluate the model using a given test condition\n",
    "def evaluate_model(cv, model):\n",
    "\t# get the dataset\n",
    "\tX, y = get_dataset()\n",
    "\t# evaluate the model\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=60, verbose=0)\n",
    "\t# return scores\n",
    "\treturn mean(scores)\n",
    "\n",
    "# define test conditions\n",
    "ideal_cv = LeaveOneOut()\n",
    "# define folds to test\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1000)\n",
    "# get the list of models to consider\n",
    "models = get_models()\n",
    "# collect results\n",
    "ideal_results, cv_results = list(), list()\n",
    "# evaluate each model\n",
    "for model in models:\n",
    "\t# evaluate model using each test condition\n",
    "\tcv_mean = evaluate_model(cv, model)\n",
    "\tideal_mean = evaluate_model(ideal_cv, model)\n",
    "\t# check for invalid results\n",
    "\tif isnan(cv_mean) or isnan(ideal_mean):\n",
    "\t\tcontinue\n",
    "\t# store results\n",
    "\tcv_results.append(cv_mean)\n",
    "\tideal_results.append(ideal_mean)\n",
    "\t# summarize progress\n",
    "\tprint('>%s: ideal=%.3f, cv=%.3f' % (type(model).__name__, ideal_mean, cv_mean))\n",
    "# calculate the correlation between each test condition\n",
    "corr, _ = pearsonr(cv_results, ideal_results)\n",
    "print('Correlation: %.3f' % corr)\n",
    "# scatter plot of results\n",
    "pyplot.scatter(cv_results, ideal_results)\n",
    "# plot the line of best fit\n",
    "coeff, bias = polyfit(cv_results, ideal_results, 1)\n",
    "line = coeff * asarray(cv_results) + bias\n",
    "pyplot.plot(cv_results, line, color='r')\n",
    "# label the plot\n",
    "pyplot.title('10-fold CV vs LOOCV Mean Accuracy')\n",
    "pyplot.xlabel('Mean Accuracy (10-fold CV)')\n",
    "pyplot.ylabel('Mean Accuracy (LOOCV)')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aff12d1",
   "metadata": {},
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy\n",
    " \n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='adam', init='glorot_uniform'):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dropout(0.4, input_shape=(pca.n_components_,)))\n",
    "\tmodel.add(Dense(12, input_dim=pca.n_components_, kernel_initializer=init, activation='relu'))\n",
    "\tmodel.add(Dense(12, kernel_initializer=init, activation='relu'))\n",
    "\tmodel.add(Dropout(0.4))\n",
    "\tmodel.add(Dense(targets.size, kernel_initializer=init, activation='relu'))\n",
    "\tmodel.add(Dense(targets.size, kernel_initializer=init, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "# fix random seed for reproducibility\n",
    "seed = 1000\n",
    "numpy.random.seed(seed)\n",
    "# create the dataset\n",
    "def get_dataset():\n",
    "    X = finalDf.copy().drop(labels = [\"gesture\",\"subject\", \"event\"], axis = 1).to_numpy()\n",
    "    y = finalDf.copy()[\"gesture\"].to_list()\n",
    "    return X, y\n",
    "\n",
    "X, Y = get_dataset()\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "cat_Y = np_utils.to_categorical(encoded_Y)\n",
    "# create model\n",
    "#model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=1500, batch_size=12, verbose=0)\n",
    "# evaluate using 10-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb5818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08b22b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39a6c7169110aaac7495196f0884d92b2fc86aacbfd209e5bf551fd1b1b877b5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
